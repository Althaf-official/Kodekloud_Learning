Task
Take a backup of the etcd cluster and save it to /opt/etcd-backup.db.

Solution
Run the following command to take a backup:

export ETCDCTL_API=3
etcdctl snapshot save --endpoints https://[127.0.0.1]:2379 --cacert /etc/kubernetes/pki/etcd/ca.crt --cert /etc/kubernetes/pki/etcd/server.crt --key=/etc/kubernetes/pki/etcd/server.key  /opt/etcd-backup.db

Details

Backup Completed

```ruby
controlplane ~ ➜  #ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379 \
  --cacert=<trusted-ca-file> --cert=<cert-file> --key=<key-file> \
  snapshot save <backup-file-location>
-bash: syntax error near unexpected token `newline'

controlplane ~ ✖ cat /etc/kubernetes/manifests/etcd.yaml | grep file
    - --cert-file=/etc/kubernetes/pki/etcd/server.crt
    - --key-file=/etc/kubernetes/pki/etcd/server.key
    - --peer-cert-file=/etc/kubernetes/pki/etcd/peer.crt
    - --peer-key-file=/etc/kubernetes/pki/etcd/peer.key
    - --peer-trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt
    - --trusted-ca-file=/etc/kubernetes/pki/etcd/ca.crt
    seccompProfile:

controlplane ~ ➜  ETCDCTL_API=3 etcdctl --endpoints=https://127.0.0.1:2379  snapshot save /opt/etcd-backup.db \
> --cacert=/etc/kubernetes/pki/etcd/ca.crt \
> --cert=/etc/kubernetes/pki/etcd/server.crt \
> --key=/etc/kubernetes/pki/etcd/server.key
Snapshot saved at /opt/etcd-backup.db

controlplane ~ ➜ 
```

Q. 2

Task
Create a Pod called redis-storage with image: redis:alpine with a Volume of type emptyDir that lasts for the life of the Pod.

Specs on the below.

Q. 3

Task
Create a new pod called super-user-pod with image busybox:1.28. Allow the pod to be able to set system_time.

The container should sleep for 4800 seconds.

Q. 4

Task
A pod definition file is created at /root/CKA/use-pv.yaml. Make use of this manifest file and mount the persistent volume called pv-1. Ensure the pod is running and the PV is bound.

mountPath: /data

persistentVolumeClaim Name: my-pvc

Solution
Add a persistentVolumeClaim definition to pod definition file.

Solution manifest file to create a pvc my-pvc as follows:

---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: my-pvc
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
       storage: 10Mi

And then, update the pod definition file as follows:

apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: use-pv
  name: use-pv
spec:
  containers:
  - image: nginx
    name: use-pv
    volumeMounts:
    - mountPath: "/data"
      name: mypd
  volumes:
    - name: mypd
      persistentVolumeClaim:
        claimName: my-pvc

Finally, create the pod by running:
kubectl create -f /root/CKA/use-pv.yaml

Details



Q. 5

Task
Create a new deployment called nginx-deploy, with image nginx:1.16 and 1 replica. Next upgrade the deployment to version 1.17 using rolling update.

Solution
Explore the --record option while creating the deployment while working with the deployment definition file. Then make use of the kubectl apply command to create or update the deployment.

To create a deployment definition file nginx-deploy:

$ kubectl create deployment nginx-deploy --image=nginx:1.16 --dry-run=client -o yaml > deploy.yaml

To create a resource from definition file and to record:

$ kubectl apply -f deploy.yaml --record

To view the history of deployment nginx-deploy:

$ kubectl rollout history deployment nginx-deploy

To upgrade the image to next given version:

$ kubectl set image deployment/nginx-deploy nginx=nginx:1.17 --record

To view the history of deployment nginx-deploy:

$ kubectl rollout history deployment nginx-deploy

Details

```ruby

controlplane ~ ➜  k create deployment nginx-deploy --image=nginx:1.16 --replicas=1 --dry-run=client -oyaml > nginxdeploy.yaml

controlplane ~ ➜  cat nginxdeploy.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    app: nginx-deploy
  name: nginx-deploy
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nginx-deploy
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: nginx-deploy
    spec:
      containers:
      - image: nginx:1.16
        name: nginx
        resources: {}
status: {}

controlplane ~ ➜  k create -f nginxdeploy.yaml --record
Flag --record has been deprecated, --record will be removed in the future
deployment.apps/nginx-deploy created

controlplane ~ ➜  k set image deployment/nginx-deploy nginx=nginx:1.17 --record
Flag --record has been deprecated, --record will be removed in the future
deployment.apps/nginx-deploy image updated

controlplane ~ ➜  k rollout history deployment nginx-deploy 
deployment.apps/nginx-deploy 
REVISION  CHANGE-CAUSE
1         kubectl create --filename=nginxdeploy.yaml --record=true
2         kubectl set image deployment/nginx-deploy nginx=nginx:1.17 --record=true


controlplane
```


Q. 6

Task
Create a new user called john. Grant him access to the cluster. John should have permission to create, list, get, update and delete pods in the development namespace . The private key exists in the location: /root/CKA/john.key and csr at /root/CKA/john.csr.

Important Note: As of kubernetes 1.19, the CertificateSigningRequest object expects a signerName.

Please refer the documentation to see an example. The documentation tab is available at the top right of terminal.

Solution
Solution manifest file to create a CSR as follows:

---
apiVersion: certificates.k8s.io/v1
kind: CertificateSigningRequest
metadata:
  name: john-developer
spec:
  signerName: kubernetes.io/kube-apiserver-client
  request: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURSBSRVFVRVNULS0tLS0KTUlJQ1ZEQ0NBVHdDQVFBd0R6RU5NQXNHQTFVRUF3d0VhbTlvYmpDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRApnZ0VQQURDQ0FRb0NnZ0VCQUt2Um1tQ0h2ZjBrTHNldlF3aWVKSzcrVVdRck04ZGtkdzkyYUJTdG1uUVNhMGFPCjV3c3cwbVZyNkNjcEJFRmVreHk5NUVydkgyTHhqQTNiSHVsTVVub2ZkUU9rbjYra1NNY2o3TzdWYlBld2k2OEIKa3JoM2prRFNuZGFvV1NPWXBKOFg1WUZ5c2ZvNUpxby82YU92czFGcEc3bm5SMG1JYWpySTlNVVFEdTVncGw4bgpjakY0TG4vQ3NEb3o3QXNadEgwcVpwc0dXYVpURTBKOWNrQmswZWhiV2tMeDJUK3pEYzlmaDVIMjZsSE4zbHM4CktiSlRuSnY3WDFsNndCeTN5WUFUSXRNclpUR28wZ2c1QS9uREZ4SXdHcXNlMTdLZDRaa1k3RDJIZ3R4UytkMEMKMTNBeHNVdzQyWVZ6ZzhkYXJzVGRMZzcxQ2NaanRxdS9YSmlyQmxVQ0F3RUFBYUFBTUEwR0NTcUdTSWIzRFFFQgpDd1VBQTRJQkFRQ1VKTnNMelBKczB2czlGTTVpUzJ0akMyaVYvdXptcmwxTGNUTStsbXpSODNsS09uL0NoMTZlClNLNHplRlFtbGF0c0hCOGZBU2ZhQnRaOUJ2UnVlMUZnbHk1b2VuTk5LaW9FMnc3TUx1a0oyODBWRWFxUjN2SSsKNzRiNnduNkhYclJsYVhaM25VMTFQVTlsT3RBSGxQeDNYVWpCVk5QaGhlUlBmR3p3TTRselZuQW5mNm96bEtxSgpvT3RORStlZ2FYWDdvc3BvZmdWZWVqc25Yd0RjZ05pSFFTbDgzSkljUCtjOVBHMDJtNyt0NmpJU3VoRllTVjZtCmlqblNucHBKZWhFUGxPMkFNcmJzU0VpaFB1N294Wm9iZDFtdWF4bWtVa0NoSzZLeGV0RjVEdWhRMi80NEMvSDIKOWk1bnpMMlRST3RndGRJZjAveUF5N05COHlOY3FPR0QKLS0tLS1FTkQgQ0VSVElGSUNBVEUgUkVRVUVTVC0tLS0tCg==
  usages:
  - digital signature
  - key encipherment
  - client auth

To approve this certificate, run: kubectl certificate approve john-developer

Next, create a role developer and rolebinding developer-role-binding, run the command:

$ kubectl create role developer --resource=pods --verb=create,list,get,update,delete --namespace=development

$ kubectl create rolebinding developer-role-binding --role=developer --user=john --namespace=development

To verify the permission from kubectl utility tool:

$ kubectl auth can-i update pods --as=john --namespace=development

Details



Q. 7

Task
Create a nginx pod called nginx-resolver using image nginx, expose it internally with a service called nginx-resolver-service. Test that you are able to look up the service and pod names from within the cluster. Use the image: busybox:1.28 for dns lookup. Record results in /root/CKA/nginx.svc and /root/CKA/nginx.pod

Solution
Use the command kubectl run and create a nginx pod and busybox pod. Resolve it, nginx service and its pod name from busybox pod.

To create a pod nginx-resolver and expose it internally:

kubectl run nginx-resolver --image=nginx
kubectl expose pod nginx-resolver --name=nginx-resolver-service --port=80 --target-port=80 --type=ClusterIP

To create a pod test-nslookup. Test that you are able to look up the service and pod names from within the cluster:

kubectl run test-nslookup --image=busybox:1.28 --rm -it --restart=Never -- nslookup nginx-resolver-service
kubectl run test-nslookup --image=busybox:1.28 --rm -it --restart=Never -- nslookup nginx-resolver-service > /root/CKA/nginx.svc

Get the IP of the nginx-resolver pod and replace the dots(.) with hyphon(-) which will be used below.

kubectl get pod nginx-resolver -o wide
kubectl run test-nslookup --image=busybox:1.28 --rm -it --restart=Never -- nslookup <P-O-D-I-P.default.pod> > /root/CKA/nginx.pod

Details

Pod: nginx-resolver created


Service DNS Resolution recorded correctly


Pod DNS resolution recorded correctly

Q. 8

Task
Create a static pod on node01 called nginx-critical with image nginx and make sure that it is recreated/restarted automatically in case of a failure.

Use /etc/kubernetes/manifests as the Static Pod path for example.

Solution
To create a static pod called nginx-critical by using below command:

kubectl run nginx-critical --image=nginx --dry-run=client -o yaml > static.yaml

Copy the contents of this file or use scp command to transfer this file from controlplane to node01 node.

root@controlplane:~# scp static.yaml node01:/root/

To know the IP Address of the node01 node:

root@controlplane:~# kubectl get nodes -o wide

# Perform SSH
root@controlplane:~# ssh node01
OR
root@controlplane:~# ssh <IP of node01>

On node01 node:

Check if static pod directory is present which is /etc/kubernetes/manifests, if it's not present then create it.

root@node01:~# mkdir -p /etc/kubernetes/manifests

Add that complete path to the staticPodPath field in the kubelet config.yaml file.

root@node01:~# vi /var/lib/kubelet/config.yaml

now, move/copy the static.yaml to path /etc/kubernetes/manifests/.

root@node01:~# cp /root/static.yaml /etc/kubernetes/manifests/

Go back to the controlplane node and check the status of static pod:

root@node01:~# exit
logout
root@controlplane:~# kubectl get pods 

Details

static pod configured under /etc/kubernetes/manifests ?


Pod nginx-critical-node01 is up and running

### Create a new user called john. Grant him access to the cluster. John should have permission to create, list, get, update and delete pods in the development namespace . The private key exists in the location: /root/CKA/john.key and csr at /root/CKA/john.csr.


Important Note: As of kubernetes 1.19, the CertificateSigningRequest object expects a signerName.

Please refer the documentation to see an example. The documentation tab is available at the top right of terminal.

CSR: john-developer Status:Approved

Role Name: developer, namespace: development, Resource: Pods

Access: User 'john' has appropriate permissions


```ruby
controlplane ~ ➜  cat /root/CKA/john.csr
-----BEGIN CERTIFICATE REQUEST-----
MIICVDCCATwCAQAwDzENMAsGA1UEAwwEam9objCCASIwDQYJKoZIhvcNAQEBBQAD
ggEPADCCAQoCggEBAKMjB52yP+rW9Mio1VhZQJny237iTUfX5bVP2enm++2fUDHk
45GiA4bOuhkH7hwpWuTGjm1FztA+5HCg67ywiT+N4k2RAwn8FGP52+CwE+vxSsrl
gsJ2nWbVzzd5MQ1rLpCYcyt6icN1qKjYVGuPgzZ/sjdO1AZnLr2wO3x6z4cIg3wP
QIjH1ZSjqOzVHMJ8mWiIQB5JzwgZ6OOy1OFACVTwygdLpLhzy9FzzWI1hdF0tvVa
09itFSH+ak5MGaAmZowoCvq6Ok6iNRhqB/7yZRSA+rxOS+eAKP+HOShZyYlbQjJe
gMt4PAQ5cQ0ZGQqOx5ZsyrCc2CNLEK8bu1y7f+sCAwEAAaAAMA0GCSqGSIb3DQEB
CwUAA4IBAQBHtZIHxh/mphoCOq+yvDHencnj7tiPcg9cvmYmtoHWETXMP6BBgWoZ
wZx7ZpOLcTLBGoEt4tCaC7QEx5fnIlnXegr29iAKDLueqyMBAKM+hTLyXOxR9MFG
CoNW7XQ0KaT7WMH/7yARXomyPhLqHeJ29wmtl9XeLRX0pZ8Zh+xLE+GN9GQM5wJt
CCZ00kauShVex6D0n1JPZPruqH1zVebhvwFqyfFJ1ScLA+0LpjwsomvxMgmULJe3
vBhVzmU7loH5iTI8+qY/5wR/tYyBPD36kTXOQlOAT5NR/Pj61wgSr3InWQs/s8ew
aWuIAVqnnVqVbwcwQX1PD9mcoRubStOI
-----END CERTIFICATE REQUEST-----

controlplane ~ ➜  vi johncsr.yaml

controlplane ~ ➜  cat /root/CKA/john.csr | base64 | tr -d "\n"
LS0tLS1CRUdJTiBDRVJUSUZJQ0FURSBSRVFVRVNULS0tLS0KTUlJQ1ZEQ0NBVHdDQVFBd0R6RU5NQXNHQTFVRUF3d0VhbTlvYmpDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRApnZ0VQQURDQ0FRb0NnZ0VCQUtNakI1MnlQK3JXOU1pbzFWaFpRSm55MjM3aVRVZlg1YlZQMmVubSsrMmZVREhrCjQ1R2lBNGJPdWhrSDdod3BXdVRHam0xRnp0QSs1SENnNjd5d2lUK040azJSQXduOEZHUDUyK0N3RSt2eFNzcmwKZ3NKMm5XYlZ6emQ1TVExckxwQ1ljeXQ2aWNOMXFLallWR3VQZ3paL3NqZE8xQVpuTHIyd08zeDZ6NGNJZzN3UApRSWpIMVpTanFPelZITUo4bVdpSVFCNUp6d2daNk9PeTFPRkFDVlR3eWdkTHBMaHp5OUZ6eldJMWhkRjB0dlZhCjA5aXRGU0grYWs1TUdhQW1ab3dvQ3ZxNk9rNmlOUmhxQi83eVpSU0ErcnhPUytlQUtQK0hPU2haeVlsYlFqSmUKZ010NFBBUTVjUTBaR1FxT3g1WnN5ckNjMkNOTEVLOGJ1MXk3ZitzQ0F3RUFBYUFBTUEwR0NTcUdTSWIzRFFFQgpDd1VBQTRJQkFRQkh0WklIeGgvbXBob0NPcSt5dkRIZW5jbmo3dGlQY2c5Y3ZtWW10b0hXRVRYTVA2QkJnV29aCndaeDdacE9MY1RMQkdvRXQ0dENhQzdRRXg1Zm5JbG5YZWdyMjlpQUtETHVlcXlNQkFLTStoVEx5WE94UjlNRkcKQ29OVzdYUTBLYVQ3V01ILzd5QVJYb215UGhMcUhlSjI5d210bDlYZUxSWDBwWjhaaCt4TEUrR045R1FNNXdKdApDQ1owMGthdVNoVmV4NkQwbjFKUFpQcnVxSDF6VmViaHZ3RnF5ZkZKMVNjTEErMExwandzb212eE1nbVVMSmUzCnZCaFZ6bVU3bG9INWlUSTgrcVkvNXdSL3RZeUJQRDM2a1RYT1FsT0FUNU5SL1BqNjF3Z1NyM0luV1FzL3M4ZXcKYVd1SUFWcW5uVnFWYndjd1FYMVBEOW1jb1J1YlN0T0kKLS0tLS1FTkQgQ0VSVElGSUNBVEUgUkVRVUVTVC0tLS0tCg==
controlplane ~ ➜  vi johncsr.yaml

controlplane ~ ➜  k create -f johncsr.yaml 
certificatesigningrequest.certificates.k8s.io/john-developer created

controlplane ~ ➜  k get csr
NAME             AGE   SIGNERNAME                                    REQUESTOR                  REQUESTEDDURATION   CONDITION
csr-b7btw        56m   kubernetes.io/kube-apiserver-client-kubelet   system:bootstrap:c04ang    <none>              Approved,Issued
csr-ssml6        57m   kubernetes.io/kube-apiserver-client-kubelet   system:node:controlplane   <none>              Approved,Issued
john-developer   8s    kubernetes.io/kube-apiserver-client           kubernetes-admin           24h                 Pending

controlplane ~ ➜  kubectl certificate approve john-developer
certificatesigningrequest.certificates.k8s.io/john-developer approved

controlplane ~ ➜  k get csr
NAME             AGE   SIGNERNAME                                    REQUESTOR                  REQUESTEDDURATION   CONDITION
csr-b7btw        57m   kubernetes.io/kube-apiserver-client-kubelet   system:bootstrap:c04ang    <none>              Approved,Issued
csr-ssml6        58m   kubernetes.io/kube-apiserver-client-kubelet   system:node:controlplane   <none>              Approved,Issued
john-developer   61s   kubernetes.io/kube-apiserver-client           kubernetes-admin           24h                 Approved,Issued

controlplane ~ ➜  kubectl get csr john-developer -oyaml
apiVersion: certificates.k8s.io/v1
kind: CertificateSigningRequest
metadata:
  creationTimestamp: "2024-05-25T06:41:57Z"
  name: john-developer
  resourceVersion: "5441"
  uid: dbd823bb-1253-494d-b2f6-a2a19a17f62c
spec:
  expirationSeconds: 86400
  groups:
  - kubeadm:cluster-admins
  - system:authenticated
  request: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURSBSRVFVRVNULS0tLS0KTUlJQ1ZEQ0NBVHdDQVFBd0R6RU5NQXNHQTFVRUF3d0VhbTlvYmpDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRApnZ0VQQURDQ0FRb0NnZ0VCQUtNakI1MnlQK3JXOU1pbzFWaFpRSm55MjM3aVRVZlg1YlZQMmVubSsrMmZVREhrCjQ1R2lBNGJPdWhrSDdod3BXdVRHam0xRnp0QSs1SENnNjd5d2lUK040azJSQXduOEZHUDUyK0N3RSt2eFNzcmwKZ3NKMm5XYlZ6emQ1TVExckxwQ1ljeXQ2aWNOMXFLallWR3VQZ3paL3NqZE8xQVpuTHIyd08zeDZ6NGNJZzN3UApRSWpIMVpTanFPelZITUo4bVdpSVFCNUp6d2daNk9PeTFPRkFDVlR3eWdkTHBMaHp5OUZ6eldJMWhkRjB0dlZhCjA5aXRGU0grYWs1TUdhQW1ab3dvQ3ZxNk9rNmlOUmhxQi83eVpSU0ErcnhPUytlQUtQK0hPU2haeVlsYlFqSmUKZ010NFBBUTVjUTBaR1FxT3g1WnN5ckNjMkNOTEVLOGJ1MXk3ZitzQ0F3RUFBYUFBTUEwR0NTcUdTSWIzRFFFQgpDd1VBQTRJQkFRQkh0WklIeGgvbXBob0NPcSt5dkRIZW5jbmo3dGlQY2c5Y3ZtWW10b0hXRVRYTVA2QkJnV29aCndaeDdacE9MY1RMQkdvRXQ0dENhQzdRRXg1Zm5JbG5YZWdyMjlpQUtETHVlcXlNQkFLTStoVEx5WE94UjlNRkcKQ29OVzdYUTBLYVQ3V01ILzd5QVJYb215UGhMcUhlSjI5d210bDlYZUxSWDBwWjhaaCt4TEUrR045R1FNNXdKdApDQ1owMGthdVNoVmV4NkQwbjFKUFpQcnVxSDF6VmViaHZ3RnF5ZkZKMVNjTEErMExwandzb212eE1nbVVMSmUzCnZCaFZ6bVU3bG9INWlUSTgrcVkvNXdSL3RZeUJQRDM2a1RYT1FsT0FUNU5SL1BqNjF3Z1NyM0luV1FzL3M4ZXcKYVd1SUFWcW5uVnFWYndjd1FYMVBEOW1jb1J1YlN0T0kKLS0tLS1FTkQgQ0VSVElGSUNBVEUgUkVRVUVTVC0tLS0tCg==
  signerName: kubernetes.io/kube-apiserver-client
  usages:
  - client auth
  username: kubernetes-admin
status:
  certificate: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUM5VENDQWQyZ0F3SUJBZ0lSQUtRQWVFMFYvNHZDeTdFcXMyOVJ0NGN3RFFZSktvWklodmNOQVFFTEJRQXcKRlRFVE1CRUdBMVVFQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5TkRBMU1qVXdOak0zTlRSYUZ3MHlOREExTWpZdwpOak0zTlRSYU1BOHhEVEFMQmdOVkJBTVRCR3B2YUc0d2dnRWlNQTBHQ1NxR1NJYjNEUUVCQVFVQUE0SUJEd0F3CmdnRUtBb0lCQVFDakl3ZWRzai9xMXZUSXFOVllXVUNaOHR0KzRrMUgxK1cxVDlucDV2dnRuMUF4NU9PUm9nT0cKenJvWkIrNGNLVnJreG81dFJjN1FQdVJ3b091OHNJay9qZUpOa1FNSi9CUmorZHZnc0JQcjhVcks1WUxDZHAxbQoxYzgzZVRFTmF5NlFtSE1yZW9uRGRhaW8yRlJyajRNMmY3STNUdFFHWnk2OXNEdDhlcytIQ0lOOEQwQ0l4OVdVCm82anMxUnpDZkpsb2lFQWVTYzhJR2VqanN0VGhRQWxVOE1vSFM2UzRjOHZSYzgxaU5ZWFJkTGIxV3RQWXJSVWgKL21wT1RCbWdKbWFNS0FyNnVqcE9valVZYWdmKzhtVVVnUHE4VGt2bmdDai9oemtvV2NtSlcwSXlYb0RMZUR3RQpPWEVOR1JrS2pzZVdiTXF3bk5nalN4Q3ZHN3RjdTMvckFnTUJBQUdqUmpCRU1CTUdBMVVkSlFRTU1Bb0dDQ3NHCkFRVUZCd01DTUF3R0ExVWRFd0VCL3dRQ01BQXdId1lEVlIwakJCZ3dGb0FVUGpXL2psa1lyZ3V0bDJaTThidDgKSmNBNWVMUXdEUVlKS29aSWh2Y05BUUVMQlFBRGdnRUJBTGx3TnZWbXZITWJzbGdXOTdlNWMyNndoS2xJb2NObApmTHRXRWZKRmtMSnNWWFFNQUxmYVRPemlQUGUyb1lNTmMwamY2ZW5maFExam14ZjdDeWJRbDhjU3NaL1duelNUCnNGdjllQkNzSXFkVXQ0clZUclVGVkxmV01xSjEwQkhEQzhYekpVbGs1L0tIUm1zc2paMGV0dzBJVFMvT0tzSkkKZ2h0TGh0SnpjVktGdm1zd0Uza0dCTzFkYlVJMzQxaGttYU9CT283cDA5L2V1Z3NjK1ZWRlpBR1RWQ0xGdHBjVgo1YWNiQ2VjZXQzNERHTHZSd2VwR3k0a0hmOGdLeFAwZGt3andUNGdaOUZieHNGeXdCTTAvOTRxNVREK2dGaGptCjZWTjlwb1pzVzhvNVpic2R1ZHd0NzcwS3lKM3NpWjlBdEgxN25Jck41UjZiekVXcXowSVcyaFU9Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
  conditions:
  - lastTransitionTime: "2024-05-25T06:42:54Z"
    lastUpdateTime: "2024-05-25T06:42:54Z"
    message: This CSR was approved by kubectl certificate approve.
    reason: KubectlApprove
    status: "True"
    type: Approved

controlplane ~ ➜  k create role --help
Create a role with single rule.

Examples:
  # Create a role named "pod-reader" that allows user to perform "get", "watch"
and "list" on pods
  kubectl create role pod-reader --verb=get --verb=list --verb=watch
--resource=pods
  
  # Create a role named "pod-reader" with ResourceName specified
  kubectl create role pod-reader --verb=get --resource=pods
--resource-name=readablepod --resource-name=anotherpod
  
  # Create a role named "foo" with API Group specified
  kubectl create role foo --verb=get,list,watch --resource=rs.apps
  
  # Create a role named "foo" with SubResource specified
  kubectl create role foo --verb=get,list,watch --resource=pods,pods/status

Options:
    --allow-missing-template-keys=true:
        If true, ignore any errors in templates when a field or map key is
        missing in the template. Only applies to golang and jsonpath output
        formats.

    --dry-run='none':
        Must be "none", "server", or "client". If client strategy, only print
        the object that would be sent, without sending it. If server strategy,
        submit server-side request without persisting the resource.

    --field-manager='kubectl-create':
        Name of the manager used to track field ownership.

    -o, --output='':
        Output format. One of: (json, yaml, name, go-template,
        go-template-file, template, templatefile, jsonpath, jsonpath-as-json,
        jsonpath-file).

    --resource=[]:
        Resource that the rule applies to

    --resource-name=[]:
        Resource in the white list that the rule applies to, repeat this flag
        for multiple items

    --save-config=false:
        If true, the configuration of current object will be saved in its
        annotation. Otherwise, the annotation will be unchanged. This flag is
        useful when you want to perform kubectl apply on this object in the
        future.

    --show-managed-fields=false:
        If true, keep the managedFields when printing objects in JSON or YAML
        format.

    --template='':
        Template string or path to template file to use when -o=go-template,
        -o=go-template-file. The template format is golang templates
        [http://golang.org/pkg/text/template/#pkg-overview].

    --validate='strict':
        Must be one of: strict (or true), warn, ignore (or false).              "true" or
        "strict" will use a schema to validate the input and fail the request
        if invalid. It will perform server side validation if
        ServerSideFieldValidation is enabled on the api-server, but will fall
        back to less reliable client-side validation if not.            "warn" will
        warn about unknown or duplicate fields without blocking the request if
        server-side field validation is enabled on the API server, and behave
        as "ignore" otherwise.          "false" or "ignore" will not perform any
        schema validation, silently dropping any unknown or duplicate fields.

    --verb=[]:
        Verb that applies to the resources contained in the rule

Usage:
  kubectl create role NAME --verb=verb --resource=resource.group/subresource
[--resource-name=resourcename] [--dry-run=server|client|none] [options]

Use "kubectl options" for a list of global command-line options (applies to all
commands).

controlplane ~ ➜  kubectl create role developer --verb=get,list,create,update,delete --reso
urce=pods -n development 
role.rbac.authorization.k8s.io/developer created

controlplane ~ ➜  k get role -n development 
NAME        CREATED AT
developer   2024-05-25T06:50:02Z

controlplane ~ ➜  k get role -n development -o wide
NAME        CREATED AT
developer   2024-05-25T06:50:02Z

controlplane ~ ➜  k describe role -n development 
Name:         developer
Labels:       <none>
Annotations:  <none>
PolicyRule:
  Resources  Non-Resource URLs  Resource Names  Verbs
  ---------  -----------------  --------------  -----
  pods       []                 []              [get list create update delete]

controlplane ~ ➜  k auth --help
Inspect authorization.

Available Commands:
  can-i         Check whether an action is allowed
  reconcile     Reconciles rules for RBAC role, role binding, cluster role, and
cluster role binding objects
  whoami        Experimental: Check self subject attributes

Usage:
  kubectl auth [flags] [options]

Use "kubectl auth <command> --help" for more information about a given command.
Use "kubectl options" for a list of global command-line options (applies to all
commands).

controlplane ~ ➜  k auth can-i --help
Check whether an action is allowed.

 VERB is a logical Kubernetes API verb like 'get', 'list', 'watch', 'delete',
etc. TYPE is a Kubernetes resource. Shortcuts and groups will be resolved.
NONRESOURCEURL is a partial URL that starts with "/". NAME is the name of a
particular Kubernetes resource. This command pairs nicely with impersonation.
See --as global flag.

Examples:
  # Check to see if I can create pods in any namespace
  kubectl auth can-i create pods --all-namespaces
  
  # Check to see if I can list deployments in my current namespace
  kubectl auth can-i list deployments.apps
  
  # Check to see if service account "foo" of namespace "dev" can list pods
  # in the namespace "prod".
  # You must be allowed to use impersonation for the global option "--as".
  kubectl auth can-i list pods --as=system:serviceaccount:dev:foo -n prod
  
  # Check to see if I can do everything in my current namespace ("*" means all)
  kubectl auth can-i '*' '*'
  
  # Check to see if I can get the job named "bar" in namespace "foo"
  kubectl auth can-i list jobs.batch/bar -n foo
  
  # Check to see if I can read pod logs
  kubectl auth can-i get pods --subresource=log
  
  # Check to see if I can access the URL /logs/
  kubectl auth can-i get /logs/
  
  # List all allowed actions in namespace "foo"
  kubectl auth can-i --list --namespace=foo

Options:
    -A, --all-namespaces=false:
        If true, check the specified action in all namespaces.

    --list=false:
        If true, prints all allowed actions.

    --no-headers=false:
        If true, prints allowed actions without headers

    -q, --quiet=false:
        If true, suppress output and just return the exit code.

    --subresource='':
        SubResource such as pod/log or deployment/scale

Usage:
  kubectl auth can-i VERB [TYPE | TYPE/NAME | NONRESOURCEURL] [options]

Use "kubectl options" for a list of global command-line options (applies to all
commands).

controlplane ~ ➜  k auth can-i create pods --namespace=development --as=john
no

controlplane ~ ✖ k auth can-i get pods --namespace=development --as=john
no

controlplane ~ ✖ k create rolebinding --help
Create a role binding for a particular role or cluster role.

Examples:
  # Create a role binding for user1, user2, and group1 using the admin cluster
role
  kubectl create rolebinding admin --clusterrole=admin --user=user1 --user=user2
--group=group1
  
  # Create a role binding for serviceaccount monitoring:sa-dev using the admin
role
  kubectl create rolebinding admin-binding --role=admin
--serviceaccount=monitoring:sa-dev

Options:
    --allow-missing-template-keys=true:
        If true, ignore any errors in templates when a field or map key is
        missing in the template. Only applies to golang and jsonpath output
        formats.

    --clusterrole='':
        ClusterRole this RoleBinding should reference

    --dry-run='none':
        Must be "none", "server", or "client". If client strategy, only print
        the object that would be sent, without sending it. If server strategy,
        submit server-side request without persisting the resource.

    --field-manager='kubectl-create':
        Name of the manager used to track field ownership.

    --group=[]:
        Groups to bind to the role. The flag can be repeated to add multiple
        groups.

    -o, --output='':
        Output format. One of: (json, yaml, name, go-template,
        go-template-file, template, templatefile, jsonpath, jsonpath-as-json,
        jsonpath-file).

    --role='':
        Role this RoleBinding should reference

    --save-config=false:
        If true, the configuration of current object will be saved in its
        annotation. Otherwise, the annotation will be unchanged. This flag is
        useful when you want to perform kubectl apply on this object in the
        future.

    --serviceaccount=[]:
        Service accounts to bind to the role, in the format
        <namespace>:<name>. The flag can be repeated to add multiple service
        accounts.

    --show-managed-fields=false:
        If true, keep the managedFields when printing objects in JSON or YAML
        format.

    --template='':
        Template string or path to template file to use when -o=go-template,
        -o=go-template-file. The template format is golang templates
        [http://golang.org/pkg/text/template/#pkg-overview].

    --user=[]:
        Usernames to bind to the role. The flag can be repeated to add
        multiple users.

    --validate='strict':
        Must be one of: strict (or true), warn, ignore (or false).              "true" or
        "strict" will use a schema to validate the input and fail the request
        if invalid. It will perform server side validation if
        ServerSideFieldValidation is enabled on the api-server, but will fall
        back to less reliable client-side validation if not.            "warn" will
        warn about unknown or duplicate fields without blocking the request if
        server-side field validation is enabled on the API server, and behave
        as "ignore" otherwise.          "false" or "ignore" will not perform any
        schema validation, silently dropping any unknown or duplicate fields.

Usage:
  kubectl create rolebinding NAME --clusterrole=NAME|--role=NAME
[--user=username] [--group=groupname]
[--serviceaccount=namespace:serviceaccountname] [--dry-run=server|client|none]
[options]

Use "kubectl options" for a list of global command-line options (applies to all
commands).

controlplane ~ ➜  kubectl create rolebinding johnrolebinding --role=developer --user=john -n development 
rolebinding.rbac.authorization.k8s.io/johnrolebinding created

controlplane ~ ➜  k describe rolebindings.rbac.authorization.k8s.io -n development 
Name:         johnrolebinding
Labels:       <none>
Annotations:  <none>
Role:
  Kind:  Role
  Name:  developer
Subjects:
  Kind  Name  Namespace
  ----  ----  ---------
  User  john  

controlplane ~ ➜  k auth can-i get pods --namespace=development --as=john
yes

controlplane ~ ➜  k auth can-i watch pod --namespace=development --as=john
no

controlplane ~ ✖ 
```
Sure, here are the important steps you performed:

1. **Created a Certificate Signing Request (CSR)**:
   - You generated a CSR using `cat /root/CKA/john.csr`.
   - You encoded the CSR in base64 format and removed the newline characters.
   - You saved the CSR into a YAML file named `johncsr.yaml`.
   - You created the CSR in Kubernetes using `kubectl create -f johncsr.yaml`.
   - You approved the CSR using `kubectl certificate approve john-developer`.

2. **Verified the CSR Approval**:
   - You checked the status of the CSR using `kubectl get csr`.
   - You confirmed the approval of the CSR using `kubectl get csr john-developer -oyaml`.

3. **Created a Role**:
   - You created a Role named `developer` with permissions to `get`, `list`, `create`, `update`, and `delete` pods in the `development` namespace using `kubectl create role developer --verb=get,list,create,update,delete --resource=pods -n development`.

4. **Verified the Role Creation**:
   - You verified the creation of the Role using `kubectl get role -n development`.

5. **Described the Role**:
   - You described the Role using `kubectl describe role -n development`.

6. **Checked Authorization**:
   - You checked whether the user `john` can create or get pods in the `development` namespace using `kubectl auth can-i create pods --namespace=development --as=john` and `kubectl auth can-i get pods --namespace=development --as=john`, respectively.

7. **Created a Role Binding**:
   - You created a Role Binding named `johnrolebinding` binding the `developer` Role to the user `john` in the `development` namespace using `kubectl create rolebinding johnrolebinding --role=developer --user=john -n development`.

8. **Verified the Role Binding**:
   - You described the Role Binding using `kubectl describe rolebindings.rbac.authorization.k8s.io -n development`.

These steps cover creating a CSR, approving it, defining roles, checking authorization, and creating role bindings, ensuring proper access control in your Kubernetes cluster.
