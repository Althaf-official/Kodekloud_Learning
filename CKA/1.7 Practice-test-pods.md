### How many pods exist on the system?

![image](https://github.com/Althaf-official/Kodekloud_Learning/assets/105126131/7ae89fb2-9a87-432e-b40f-f99558aa507f)

### Create a new pod with the nginx image.

Run the command: ```kubectl run nginx --image=nginx```


![image](https://github.com/Althaf-official/Kodekloud_Learning/assets/105126131/fd8d98fd-a6a5-466c-a7e4-9ddbf31ae768)

### How many pods are created now?

![image](https://github.com/Althaf-official/Kodekloud_Learning/assets/105126131/c2f94f51-ea2f-4d3a-86fb-f6027224473c)


### What is the image used to create the new pods?

```ruby
controlplane ~ ➜  kubectl get pods
NAME            READY   STATUS    RESTARTS   AGE
nginx           1/1     Running   0          110s
newpods-pgfsj   1/1     Running   0          35s
newpods-tn68q   1/1     Running   0          35s
newpods-n6kzs   1/1     Running   0          35s

controlplane ~ ➜  kubectl describe pod newpods-pgfsj 
Name:             newpods-pgfsj
Namespace:        default
Priority:         0
Service Account:  default
Node:             controlplane/192.22.247.3
Start Time:       Tue, 30 Jan 2024 11:14:25 +0000
Labels:           tier=busybox
Annotations:      <none>
Status:           Running
IP:               10.42.0.12
IPs:
  IP:           10.42.0.12
Controlled By:  ReplicaSet/newpods
Containers:
  busybox:
    Container ID:  containerd://e32b1bebcb948e2bbb547fa725b7d9344c1005ddd3a7dd1bbf7cc222520d0589
    Image:         busybox
    Image ID:      docker.io/library/busybox@sha256:6d9ac9237a84afe1516540f40a0fafdc86859b2141954b4d643af7066d598b74
    Port:          <none>
    Host Port:     <none>
    Command:
      sleep
      1000
    State:          Running
      Started:      Tue, 30 Jan 2024 11:14:27 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-54grg (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             True 
  ContainersReady   True 
  PodScheduled      True 
Volumes:
  kube-api-access-54grg:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type    Reason     Age    From               Message
  ----    ------     ----   ----               -------
  Normal  Scheduled  2m51s  default-scheduler  Successfully assigned default/newpods-pgfsj to controlplane
  Normal  Pulling    2m50s  kubelet            Pulling image "busybox"
  Normal  Pulled     2m50s  kubelet            Successfully pulled image "busybox" in 297.501855ms (297.517631ms including waiting)
  Normal  Created    2m50s  kubelet            Created container busybox
  Normal  Started    2m49s  kubelet            Started container busybox

controlplane ~ ➜  
```

### Which nodes are these pods placed on?

![image](https://github.com/Althaf-official/Kodekloud_Learning/assets/105126131/f49faef2-b813-427d-a86f-868e6ef9a856)


Run the command kubectl describe pod newpods-<id> and look at the node field.
Alternatively run ```kubectl get pods -o wide``` and check for the node the pod is placed on.

![image](https://github.com/Althaf-official/Kodekloud_Learning/assets/105126131/8f5fafe5-55d2-43fb-90e8-d488084e8642)



## How many containers are part of the pod webapp?

```ruby
controlplane ~ ➜  kubectl get pod
NAME            READY   STATUS             RESTARTS   AGE
nginx           1/1     Running            0          7m58s
newpods-pgfsj   1/1     Running            0          6m43s
newpods-tn68q   1/1     Running            0          6m43s
newpods-n6kzs   1/1     Running            0          6m43s
webapp          1/2     ImagePullBackOff   0          48s

controlplane ~ ➜  kubectl describe pod webapp 
Name:             webapp
Namespace:        default
Priority:         0
Service Account:  default
Node:             controlplane/192.22.247.3
Start Time:       Tue, 30 Jan 2024 11:20:20 +0000
Labels:           <none>
Annotations:      <none>
Status:           Pending
IP:               10.42.0.13
IPs:
  IP:  10.42.0.13
Containers:
  nginx:
    Container ID:   containerd://317e7552d04753ce5adb3ea842fafafbed14cf333f1ca7feac171a410e34eb30
    Image:          nginx
    Image ID:       docker.io/library/nginx@sha256:4c0fdaa8b6341bfdeca5f18f7837462c80cff90527ee35ef185571e1c327beac
    Port:           <none>
    Host Port:      <none>
    State:          Running
      Started:      Tue, 30 Jan 2024 11:20:21 +0000
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-pctt7 (ro)
  agentx:
    Container ID:   
    Image:          agentx
    Image ID:       
    Port:           <none>
    Host Port:      <none>
    State:          Waiting
      Reason:       ErrImagePull
    Ready:          False
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-pctt7 (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             False 
  ContainersReady   False 
  PodScheduled      True 
Volumes:
  kube-api-access-pctt7:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type     Reason     Age                From               Message
  ----     ------     ----               ----               -------
  Normal   Scheduled  62s                default-scheduler  Successfully assigned default/webapp to controlplane
  Normal   Pulling    62s                kubelet            Pulling image "nginx"
  Normal   Pulled     61s                kubelet            Successfully pulled image "nginx" in 179.06871ms (179.092308ms including waiting)
  Normal   Created    61s                kubelet            Created container nginx
  Normal   Started    61s                kubelet            Started container nginx
  Normal   Pulling    23s (x3 over 61s)  kubelet            Pulling image "agentx"
  Warning  Failed     23s (x3 over 61s)  kubelet            Failed to pull image "agentx": rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/agentx:latest": failed to resolve reference "docker.io/library/agentx:latest": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed
  Warning  Failed     23s (x3 over 61s)  kubelet            Error: ErrImagePull
  Normal   BackOff    11s (x4 over 61s)  kubelet            Back-off pulling image "agentx"
  Warning  Failed     11s (x4 over 61s)  kubelet            Error: ImagePullBackOff

controlplane ~ ➜  
```

## What images are used in the new webapp pod?

nginx & agentx

![image](https://github.com/Althaf-official/Kodekloud_Learning/assets/105126131/f2e6b23b-55fd-4880-8e5c-6c397b01b581)

## What is the state of the container agentx in the pod webapp?


Wait for it to finish the ContainerCreating state

![image](https://github.com/Althaf-official/Kodekloud_Learning/assets/105126131/5a7d881d-0722-4a0b-ad0e-4d3c8bbab8fe)

Run the command kubectl describe pod webapp and look at the state of the agentx container.

## Why do you think the container agentx in pod webapp is in error?

Run the command kubectl describe pod webapp and look under the events section.
An image by that name does not exist in DockerHub.

```ruby
Events:
  Type     Reason     Age                    From               Message
  ----     ------     ----                   ----               -------
  Normal   Scheduled  6m38s                  default-scheduler  Successfully assigned default/webapp to controlplane
  Normal   Pulling    6m38s                  kubelet            Pulling image "nginx"
  Normal   Pulled     6m37s                  kubelet            Successfully pulled image "nginx" in 179.06871ms (179.092308ms including waiting)
  Normal   Created    6m37s                  kubelet            Created container nginx
  Normal   Started    6m37s                  kubelet            Started container nginx
  Warning  Failed     5m59s (x3 over 6m37s)  kubelet            Error: ErrImagePull
  Warning  Failed     5m32s (x5 over 6m37s)  kubelet            Error: ImagePullBackOff
  Normal   Pulling    5m17s (x4 over 6m37s)  kubelet            Pulling image "agentx"
  Warning  Failed     5m17s (x4 over 6m37s)  kubelet            Failed to pull image "agentx": rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/agentx:latest": failed to resolve reference "docker.io/library/agentx:latest": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed
  Normal   BackOff    92s (x21 over 6m37s)   kubelet            Back-off pulling image "agentx"
```

## What does the READY column in the output of the kubectl get pods command indicate?

Running Containers in POD/Total Containers in POD

![image](https://github.com/Althaf-official/Kodekloud_Learning/assets/105126131/8b9a354c-8b9d-4ddd-b348-f8bb7e3ca761)

## Delete the webapp Pod.


Once deleted, wait for the pod to fully terminate.

```ruby
controlplane ~ ➜  kubectl delete pod webapp 
pod "webapp" deleted

controlplane ~ ➜  kubectl get pod
NAME            READY   STATUS    RESTARTS   AGE
nginx           1/1     Running   0          17m
newpods-pgfsj   1/1     Running   0          16m
newpods-tn68q   1/1     Running   0          16m
newpods-n6kzs   1/1     Running   0          16m

controlplane ~ ➜  
```

## Create a new pod with the name redis and the image redis123.


Use a pod-definition YAML file. And yes the image name is wrong!


 We use kubectl run command with ```--dry-run=client -o yaml``` option to create a manifest file :-
    kubectl run redis --image=redis123 --dry-run=client -o yaml > redis-definition.yaml


After that, using kubectl create -f command to create a resource from the manifest file :-

    kubectl create -f redis-definition.yaml 
Verify the work by running kubectl get command :-

    kubectl get pods

```ruby
controlplane ~ ➜  kubectl run redis --image=redis123 --dry-run=client -o yaml > redis-definition.yaml

controlplane ~ ➜  ls
redis-definition.yaml  sample.yaml

controlplane ~ ➜  cat redis-definition.yaml 
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: redis
  name: redis
spec:
  containers:
  - image: redis123
    name: redis
    resources: {}
  dnsPolicy: ClusterFirst
  restartPolicy: Always
status: {}
controlplane ~ ➜  kubectl create -f redis-definition.yaml 
pod/redis created

controlplane ~ ➜  kubectl get pod
NAME            READY   STATUS         RESTARTS        AGE
nginx           1/1     Running        0               25m
newpods-tn68q   1/1     Running        1 (7m57s ago)   24m
newpods-n6kzs   1/1     Running        1 (7m57s ago)   24m
newpods-pgfsj   1/1     Running        1 (7m57s ago)   24m
redis           0/1     ErrImagePull   0     

```

## Now change the image on this pod to redis

Use the kubectl edit command to update the image of the pod to redis.

    kubectl edit pod redis

    
If you used a pod definition file then update the image from redis123 to redis in the definition file via Vi or Nano editor and then run kubectl apply command to update the image :-

    kubectl apply -f redis-definition.yaml 
