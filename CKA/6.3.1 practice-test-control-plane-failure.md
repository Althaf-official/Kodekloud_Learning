### The cluster is broken. We tried deploying an application but it's not working. Troubleshoot and fix the issue.


Start looking at the deployments.

Check the status of all control plane components and identify the component's pod which has an issue.


-------

Run the command: kubectl get pods -n kube-system and check the status of kube-scheduler pod.
We need to check the kube-scheduler manifest file to fix the issue.



The command run by the scheduler pod is incorrect. Here is a snippet of the YAML file.

    spec:
      containers:
      - command:
        - kube-scheduler
        - --authentication-kubeconfig=/etc/kubernetes/scheduler.conf
        - --authorization-kubeconfig=/etc/kubernetes/scheduler.conf
        - --bind-address=127.0.0.1
        - --kubeconfig=/etc/kubernetes/scheduler.conf
        - --leader-elect=true
        ....
Once this is corrected, the scheduler pod will be recreated.


```ruby
controlplane ~ ➜  cat /etc/kubernetes/manifests/
etcd.yaml                     kube-controller-manager.yaml  kube-scheduler.yaml
kube-apiserver.yaml           .kubelet-keep                 

controlplane ~ ➜  cat /etc/kubernetes/manifests/
etcd.yaml                     kube-controller-manager.yaml  kube-scheduler.yaml
kube-apiserver.yaml           .kubelet-keep                 

controlplane ~ ➜  cat /etc/kubernetes/manifests/kube-scheduler.yaml 
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    component: kube-scheduler
    tier: control-plane
  name: kube-scheduler
  namespace: kube-system
spec:
  containers:
  - command:
    - kube-schedulerrrr
    - --authentication-kubeconfig=/etc/kubernetes/scheduler.conf
    - --authorization-kubeconfig=/etc/kubernetes/scheduler.conf
    - --bind-address=127.0.0.1
    - --kubeconfig=/etc/kubernetes/scheduler.conf
    - --leader-elect=true
    image: registry.k8s.io/kube-scheduler:v1.29.0
    imagePullPolicy: IfNotPresent
    livenessProbe:
      failureThreshold: 8
      httpGet:
        host: 127.0.0.1
        path: /healthz
        port: 10259
        scheme: HTTPS
      initialDelaySeconds: 10
      periodSeconds: 10
      timeoutSeconds: 15
    name: kube-scheduler
    resources:
      requests:
        cpu: 100m
    startupProbe:
      failureThreshold: 24
      httpGet:
        host: 127.0.0.1
        path: /healthz
        port: 10259
        scheme: HTTPS
      initialDelaySeconds: 10
      periodSeconds: 10
      timeoutSeconds: 15
    volumeMounts:
    - mountPath: /etc/kubernetes/scheduler.conf
      name: kubeconfig
      readOnly: true
  hostNetwork: true
  priority: 2000001000
  priorityClassName: system-node-critical
  securityContext:
    seccompProfile:
      type: RuntimeDefault
  volumes:
  - hostPath:
      path: /etc/kubernetes/scheduler.conf
      type: FileOrCreate
    name: kubeconfig
status: {}

controlplane ~ ➜  vi /etc/kubernetes/manifests/kube-scheduler.yaml 

controlplane ~ ➜  k get all
NAME                       READY   STATUS    RESTARTS   AGE
pod/app-5646649cc9-2ktpt   0/1     Pending   0          20m

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   25m

NAME                  READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/app   0/1     1            0           20m

NAME                             DESIRED   CURRENT   READY   AGE
replicaset.apps/app-5646649cc9   1         1         0       20m

controlplane ~ ➜  k get pod -n kube-system 
NAME                                   READY   STATUS    RESTARTS   AGE
coredns-69f9c977-4jtb2                 1/1     Running   0          25m
coredns-69f9c977-rs97l                 1/1     Running   0          25m
etcd-controlplane                      1/1     Running   0          25m
kube-apiserver-controlplane            1/1     Running   0          25m
kube-controller-manager-controlplane   1/1     Running   0          25m
kube-proxy-7c6sj                       1/1     Running   0          25m
kube-scheduler-controlplane            0/1     Running   0          11s

controlplane ~ ➜  k get pod -n kube-system 
NAME                                   READY   STATUS    RESTARTS   AGE
coredns-69f9c977-4jtb2                 1/1     Running   0          25m
coredns-69f9c977-rs97l                 1/1     Running   0          25m
etcd-controlplane                      1/1     Running   0          25m
kube-apiserver-controlplane            1/1     Running   0          26m
kube-controller-manager-controlplane   1/1     Running   0          25m
kube-proxy-7c6sj                       1/1     Running   0          25m
kube-scheduler-controlplane            0/1     Running   0          19s

controlplane ~ ➜  k get pod -n kube-system 
NAME                                   READY   STATUS    RESTARTS   AGE
coredns-69f9c977-4jtb2                 1/1     Running   0          25m
coredns-69f9c977-rs97l                 1/1     Running   0          25m
etcd-controlplane                      1/1     Running   0          26m
kube-apiserver-controlplane            1/1     Running   0          26m
kube-controller-manager-controlplane   1/1     Running   0          26m
kube-proxy-7c6sj                       1/1     Running   0          25m
kube-scheduler-controlplane            1/1     Running   0          25s

controlplane ~ ➜  k get pod
NAME                   READY   STATUS    RESTARTS   AGE
app-5646649cc9-2ktpt   1/1     Running   0          21m

controlplane ~ ➜  
```


### Scale the deployment app to 2 pods.


Run the command: 

        kubectl scale deploy app --replicas=2



```ruby

controlplane ~ ➜  k get all
NAME                       READY   STATUS    RESTARTS   AGE
pod/app-5646649cc9-t7h8x   1/1     Running   0          4m8s

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   15m

NAME                  READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/app   1/1     1            1           4m8s

NAME                             DESIRED   CURRENT   READY   AGE
replicaset.apps/app-5646649cc9   1         1         1       4m8s

controlplane ~ ➜  k scale deployment app --replicas=2
deployment.apps/app scaled

controlplane ~ ➜  k get all
NAME                       READY   STATUS    RESTARTS   AGE
pod/app-5646649cc9-t7h8x   1/1     Running   0          7m11s

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   18m

NAME                  READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/app   1/2     1            1           7m11s

NAME                             DESIRED   CURRENT   READY   AGE
replicaset.apps/app-5646649cc9   1         1         1       7m11s

controlplane ~ ➜  k get all
NAME                       READY   STATUS    RESTARTS   AGE
pod/app-5646649cc9-t7h8x   1/1     Running   0          7m26s

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   18m

NAME                  READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/app   1/2     1            1           7m26s

NAME                             DESIRED   CURRENT   READY   AGE
replicaset.apps/app-5646649cc9   1         1         1       7m26s

controlplane ~ ➜  k get all
NAME                       READY   STATUS    RESTARTS   AGE
pod/app-5646649cc9-t7h8x   1/1     Running   0          7m32s

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   18m

NAME                  READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/app   1/2     1            1           7m32s

NAME                             DESIRED   CURRENT   READY   AGE
replicaset.apps/app-5646649cc9   1         1         1       7m32s

controlplane ~ ➜  k describe deployments.apps app 
Name:                   app
Namespace:              default
CreationTimestamp:      Mon, 20 May 2024 04:25:52 +0000
Labels:                 app=app
Annotations:            deployment.kubernetes.io/revision: 1
Selector:               app=app
Replicas:               2 desired | 1 updated | 1 total | 1 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=app
  Containers:
   nginx:
    Image:        nginx:alpine
    Port:         <none>
    Host Port:    <none>
    Environment:  <none>
    Mounts:       <none>
  Volumes:        <none>
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  <none>
NewReplicaSet:   app-5646649cc9 (1/1 replicas created)
Events:
  Type    Reason             Age    From                   Message
  ----    ------             ----   ----                   -------
  Normal  ScalingReplicaSet  8m22s  deployment-controller  Scaled up replica set app-5646649cc9 to 1

controlplane ~ ➜  k get all
NAME                       READY   STATUS    RESTARTS   AGE
pod/app-5646649cc9-t7h8x   1/1     Running   0          8m41s

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   19m

NAME                  READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/app   1/2     1            1           8m41s

NAME                             DESIRED   CURRENT   READY   AGE
replicaset.apps/app-5646649cc9   1         1         1       8m41s

controlplane ~ ➜  k get all
NAME                       READY   STATUS    RESTARTS   AGE
pod/app-5646649cc9-t7h8x   1/1     Running   0          9m16s

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   20m

NAME                  READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/app   1/2     1            1           9m16s

NAME                             DESIRED   CURRENT   READY   AGE
replicaset.apps/app-5646649cc9   1         1         1       9m16s



```


### Even though the deployment was scaled to 2, the number of PODs does not seem to increase. Investigate and fix the issue.


Inspect the component responsible for managing ```deployments``` and ```replicasets```.



Run the command: ```kubectl get po -n kube-system``` and check the logs of kube-controller-manager pod to know the failure reason by running command: ```kubectl logs -n kube-system kube-controller-manager-controlplane```

Then check the kube-controller-manager configuration file at /etc/kubernetes/manifests/kube-controller-manager.yaml and fix the issue.

        root@controlplane:/etc/kubernetes/manifests# kubectl -n kube-system logs kube-controller-manager-controlplane
        I0916 13:10:47.059336       1 serving.go:348] Generated self-signed cert in-memory
        stat /etc/kubernetes/controller-manager-XXXX.conf: no such file or directory

        root@controlplane:/etc/kubernetes/manifests# 
        The configuration file specified (/etc/kubernetes/controller-manager-XXXX.conf) does not exist.
        Correct the path: /etc/kubernetes/controller-manager.conf



```ruby

controlplane ~ ➜  k get all
NAME                       READY   STATUS    RESTARTS   AGE
pod/app-5646649cc9-t7h8x   1/1     Running   0          9m16s

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   20m

NAME                  READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/app   1/2     1            1           9m16s

NAME                             DESIRED   CURRENT   READY   AGE
replicaset.apps/app-5646649cc9   1         1         1       9m16s

controlplane ~ ➜
controlplane /etc/kubernetes ➜  k get pod -n kube-system 
NAME                                   READY   STATUS             RESTARTS      AGE
coredns-69f9c977-88s47                 1/1     Running            0             37m
coredns-69f9c977-vkp8z                 1/1     Running            0             37m
etcd-controlplane                      1/1     Running            0             37m
kube-apiserver-controlplane            1/1     Running            0             37m
kube-controller-manager-controlplane   0/1     CrashLoopBackOff   9 (40s ago)   26s
kube-proxy-6lnm2                       1/1     Running            0             37m
kube-scheduler-controlplane            1/1     Running            0             22m

controlplane /etc/kubernetes ➜  k create -f /tmp/kubectl-edit-206893329.yaml 
Error from server (AlreadyExists): error when creating "/tmp/kubectl-edit-206893329.yaml": pods "kube-controller-manager-controlplane" already exists

controlplane /etc/kubernetes ✖ ls
admin.conf               kubelet.conf  pki             super-admin.conf
controller-manager.conf  manifests     scheduler.conf

controlplane /etc/kubernetes ➜  cd manifests/

controlplane /etc/kubernetes/manifests ➜  ls
etcd.yaml  kube-apiserver.yaml  kube-controller-manager.yaml  kube-scheduler.yaml

controlplane /etc/kubernetes/manifests ➜  cat kube-
cat: kube-: No such file or directory

controlplane /etc/kubernetes/manifests ✖ cat kube-controller-manager.yaml 
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    component: kube-controller-manager
    tier: control-plane
  name: kube-controller-manager
  namespace: kube-system
spec:
  containers:
  - command:
    - kube-controller-manager
    - --allocate-node-cidrs=true
    - --authentication-kubeconfig=/etc/kubernetes/controller-manager.conf
    - --authorization-kubeconfig=/etc/kubernetes/controller-manager.conf
    - --bind-address=127.0.0.1
    - --client-ca-file=/etc/kubernetes/pki/ca.crt
    - --cluster-cidr=10.244.0.0/16
    - --cluster-name=kubernetes
    - --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt
    - --cluster-signing-key-file=/etc/kubernetes/pki/ca.key
    - --controllers=*,bootstrapsigner,tokencleaner
    - --kubeconfig=/etc/kubernetes/controller-manager-XXXX.conf
    - --leader-elect=true
    - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
    - --root-ca-file=/etc/kubernetes/pki/ca.crt
    - --service-account-private-key-file=/etc/kubernetes/pki/sa.key
    - --service-cluster-ip-range=10.96.0.0/12
    - --use-service-account-credentials=true
    image: registry.k8s.io/kube-controller-manager:v1.29.0
    imagePullPolicy: IfNotPresent
    livenessProbe:
      failureThreshold: 8
      httpGet:
        host: 127.0.0.1
        path: /healthz
        port: 10257
        scheme: HTTPS
      initialDelaySeconds: 10
      periodSeconds: 10
      timeoutSeconds: 15
    name: kube-controller-manager
    resources:
      requests:
        cpu: 200m
    startupProbe:
      failureThreshold: 24
      httpGet:
        host: 127.0.0.1
        path: /healthz
        port: 10257
        scheme: HTTPS
      initialDelaySeconds: 10
      periodSeconds: 10
      timeoutSeconds: 15
    volumeMounts:
    - mountPath: /etc/ssl/certs
      name: ca-certs
      readOnly: true
    - mountPath: /etc/ca-certificates
      name: etc-ca-certificates
      readOnly: true
    - mountPath: /usr/libexec/kubernetes/kubelet-plugins/volume/exec
      name: flexvolume-dir
    - mountPath: /etc/kubernetes/pki
      name: k8s-certs
      readOnly: true
    - mountPath: /etc/kubernetes/controller-manager.conf
      name: kubeconfig
      readOnly: true
    - mountPath: /usr/local/share/ca-certificates
      name: usr-local-share-ca-certificates
      readOnly: true
    - mountPath: /usr/share/ca-certificates
      name: usr-share-ca-certificates
      readOnly: true
  hostNetwork: true
  priority: 2000001000
  priorityClassName: system-node-critical
  securityContext:
    seccompProfile:
      type: RuntimeDefault
  volumes:
  - hostPath:
      path: /etc/ssl/certs
      type: DirectoryOrCreate
    name: ca-certs
  - hostPath:
      path: /etc/ca-certificates
      type: DirectoryOrCreate
    name: etc-ca-certificates
  - hostPath:
      path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec
      type: DirectoryOrCreate
    name: flexvolume-dir
  - hostPath:
      path: /etc/kubernetes/pki
      type: DirectoryOrCreate
    name: k8s-certs
  - hostPath:
      path: /etc/kubernetes/controller-manager.conf
      type: FileOrCreate
    name: kubeconfig
  - hostPath:
      path: /usr/local/share/ca-certificates
      type: DirectoryOrCreate
    name: usr-local-share-ca-certificates
  - hostPath:
      path: /usr/share/ca-certificates
      type: DirectoryOrCreate
    name: usr-share-ca-certificates
status: {}

controlplane /etc/kubernetes/manifests ➜  vi kube-controller-manager.yaml 

controlplane /etc/kubernetes/manifests ➜  k get all
NAME                       READY   STATUS    RESTARTS   AGE
pod/app-5646649cc9-t7h8x   1/1     Running   0          30m

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   41m

NAME                  READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/app   1/2     1            1           30m

NAME                             DESIRED   CURRENT   READY   AGE
replicaset.apps/app-5646649cc9   1         1         1       30m

controlplane /etc/kubernetes/manifests ➜  k get pod -n kube-system 
NAME                                   READY   STATUS    RESTARTS   AGE
coredns-69f9c977-88s47                 1/1     Running   0          41m
coredns-69f9c977-vkp8z                 1/1     Running   0          41m
etcd-controlplane                      1/1     Running   0          41m
kube-apiserver-controlplane            1/1     Running   0          41m
kube-controller-manager-controlplane   0/1     Running   0          11s
kube-proxy-6lnm2                       1/1     Running   0          41m
kube-scheduler-controlplane            1/1     Running   0          26m

controlplane /etc/kubernetes/manifests ➜  k get pod
NAME                   READY   STATUS    RESTARTS   AGE
app-5646649cc9-df2f9   1/1     Running   0          3s
app-5646649cc9-t7h8x   1/1     Running   0          30m

controlplane /etc/kubernetes/manifests ➜  k get all 
NAME                       READY   STATUS    RESTARTS   AGE
pod/app-5646649cc9-df2f9   1/1     Running   0          14s
pod/app-5646649cc9-t7h8x   1/1     Running   0          30m

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   42m

NAME                  READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/app   2/2     2            2           30m

NAME                             DESIRED   CURRENT   READY   AGE
replicaset.apps/app-5646649cc9   2         2         2       30m

controlplane /etc/kubernetes/manifests ➜  ls
etcd.yaml  kube-apiserver.yaml  kube-controller-manager.yaml  kube-scheduler.yaml

controlplane /etc/kubernetes/manifests ➜  cat kube-controller-manager.yaml 
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    component: kube-controller-manager
    tier: control-plane
  name: kube-controller-manager
  namespace: kube-system
spec:
  containers:
  - command:
    - kube-controller-manager
    - --allocate-node-cidrs=true
    - --authentication-kubeconfig=/etc/kubernetes/controller-manager.conf
    - --authorization-kubeconfig=/etc/kubernetes/controller-manager.conf
    - --bind-address=127.0.0.1
    - --client-ca-file=/etc/kubernetes/pki/ca.crt
    - --cluster-cidr=10.244.0.0/16
    - --cluster-name=kubernetes
    - --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt
    - --cluster-signing-key-file=/etc/kubernetes/pki/ca.key
    - --controllers=*,bootstrapsigner,tokencleaner
    - --kubeconfig=/etc/kubernetes/controller-manager.conf
    - --leader-elect=true
    - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
    - --root-ca-file=/etc/kubernetes/pki/ca.crt
    - --service-account-private-key-file=/etc/kubernetes/pki/sa.key
    - --service-cluster-ip-range=10.96.0.0/12
    - --use-service-account-credentials=true
    image: registry.k8s.io/kube-controller-manager:v1.29.0
    imagePullPolicy: IfNotPresent
    livenessProbe:
      failureThreshold: 8
      httpGet:
        host: 127.0.0.1
        path: /healthz
        port: 10257
        scheme: HTTPS
      initialDelaySeconds: 10
      periodSeconds: 10
      timeoutSeconds: 15
    name: kube-controller-manager
    resources:
      requests:
        cpu: 200m
    startupProbe:
      failureThreshold: 24
      httpGet:
        host: 127.0.0.1
        path: /healthz
        port: 10257
        scheme: HTTPS
      initialDelaySeconds: 10
      periodSeconds: 10
      timeoutSeconds: 15
    volumeMounts:
    - mountPath: /etc/ssl/certs
      name: ca-certs
      readOnly: true
    - mountPath: /etc/ca-certificates
      name: etc-ca-certificates
      readOnly: true
    - mountPath: /usr/libexec/kubernetes/kubelet-plugins/volume/exec
      name: flexvolume-dir
    - mountPath: /etc/kubernetes/pki
      name: k8s-certs
      readOnly: true
    - mountPath: /etc/kubernetes/controller-manager.conf
      name: kubeconfig
      readOnly: true
    - mountPath: /usr/local/share/ca-certificates
      name: usr-local-share-ca-certificates
      readOnly: true
    - mountPath: /usr/share/ca-certificates
      name: usr-share-ca-certificates
      readOnly: true
  hostNetwork: true
  priority: 2000001000
  priorityClassName: system-node-critical
  securityContext:
    seccompProfile:
      type: RuntimeDefault
  volumes:
  - hostPath:
      path: /etc/ssl/certs
      type: DirectoryOrCreate
    name: ca-certs
  - hostPath:
      path: /etc/ca-certificates
      type: DirectoryOrCreate
    name: etc-ca-certificates
  - hostPath:
      path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec
      type: DirectoryOrCreate
    name: flexvolume-dir
  - hostPath:
      path: /etc/kubernetes/pki
      type: DirectoryOrCreate
    name: k8s-certs
  - hostPath:
      path: /etc/kubernetes/controller-manager.conf
      type: FileOrCreate
    name: kubeconfig
  - hostPath:
      path: /usr/local/share/ca-certificates
      type: DirectoryOrCreate
    name: usr-local-share-ca-certificates
  - hostPath:
      path: /usr/share/ca-certificates
      type: DirectoryOrCreate
    name: usr-share-ca-certificates
status: {}

controlplane /etc/kubernetes/manifests ➜  
```





###  Something is wrong with scaling again. We just tried scaling the deployment to 3 replicas. But it's not happening.


Investigate and fix the issue.





Check the volume mount path in kube-controller-manager manifest file at /etc/kubernetes/manifests.
Just as we did in the previous question, inspect the logs of the kube-controller-manager pod:

        root@controlplane:/etc/kubernetes/manifests# kubectl -n kube-system logs kube-controller-manager-controlplane
        I0916 13:17:27.452539       1 serving.go:348] Generated self-signed cert in-memory
        unable to load client CA provider: open /etc/kubernetes/pki/ca.crt: no such file or directory

        root@controlplane:/etc/kubernetes/manifests# 
It appears the path /etc/kubernetes/pki is not mounted from the controlplane to the kube-controller-manager pod. If we inspect the pod manifest file, we can see that the incorrect hostPath is used for the volume:

WRONG:

        - hostPath:
              path: /etc/kubernetes/WRONG-PKI-DIRECTORY
              type: DirectoryOrCreate
CORRECT:

        - hostPath: 
            path: /etc/kubernetes/pki 
            type: DirectoryOrCreate 
Once the path is corrected, the pod will be recreated and our deployment should eventually scale up to 3 replicas.




```ruby

controlplane ~ ➜  k get all -n kube-system 
NAME                                       READY   STATUS             RESTARTS      AGE
pod/coredns-69f9c977-88s47                 1/1     Running            0             48m
pod/coredns-69f9c977-vkp8z                 1/1     Running            0             48m
pod/etcd-controlplane                      1/1     Running            0             48m
pod/kube-apiserver-controlplane            1/1     Running            0             48m
pod/kube-controller-manager-controlplane   0/1     CrashLoopBackOff   4 (10s ago)   98s
pod/kube-proxy-6lnm2                       1/1     Running            0             48m
pod/kube-scheduler-controlplane            1/1     Running            0             33m

NAME               TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                  AGE
service/kube-dns   ClusterIP   10.96.0.10   <none>        53/UDP,53/TCP,9153/TCP   48m

NAME                        DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
daemonset.apps/kube-proxy   1         1         1       1            1           kubernetes.io/os=linux   48m

NAME                      READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/coredns   2/2     2            2           48m

NAME                               DESIRED   CURRENT   READY   AGE
replicaset.apps/coredns-69f9c977   2         2         2       48m

controlplane ~ ➜  k -n kube-system describe pod kube-controller-manager-controlplane 
Name:                 kube-controller-manager-controlplane
Namespace:            kube-system
Priority:             2000001000
Priority Class Name:  system-node-critical
Node:                 controlplane/192.5.224.6
Start Time:           Mon, 20 May 2024 04:56:03 +0000
Labels:               component=kube-controller-manager
                      tier=control-plane
Annotations:          kubernetes.io/config.hash: f3acd5d8bac629a5bb29ac545fabcc86
                      kubernetes.io/config.mirror: f3acd5d8bac629a5bb29ac545fabcc86
                      kubernetes.io/config.seen: 2024-05-20T05:01:50.817835092Z
                      kubernetes.io/config.source: file
Status:               Running
SeccompProfile:       RuntimeDefault
IP:                   192.5.224.6
IPs:
  IP:           192.5.224.6
Controlled By:  Node/controlplane
Containers:
  kube-controller-manager:
    Container ID:  containerd://3c4aebd9d6f1f3022881edadc9aa83a0a3fe9ef24d002aaabb21e16742ba129b
    Image:         registry.k8s.io/kube-controller-manager:v1.29.0
    Image ID:      registry.k8s.io/kube-controller-manager@sha256:d1e38ea25b27e57b41995ef59ad76dd33481853a5b8d1a91abb7a8be32b7e7da
    Port:          <none>
    Host Port:     <none>
    Command:
      kube-controller-manager
      --allocate-node-cidrs=true
      --authentication-kubeconfig=/etc/kubernetes/controller-manager.conf
      --authorization-kubeconfig=/etc/kubernetes/controller-manager.conf
      --bind-address=127.0.0.1
      --client-ca-file=/etc/kubernetes/pki/ca.crt
      --cluster-cidr=10.244.0.0/16
      --cluster-name=kubernetes
      --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt
      --cluster-signing-key-file=/etc/kubernetes/pki/ca.key
      --controllers=*,bootstrapsigner,tokencleaner
      --kubeconfig=/etc/kubernetes/controller-manager.conf
      --leader-elect=true
      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
      --root-ca-file=/etc/kubernetes/pki/ca.crt
      --service-account-private-key-file=/etc/kubernetes/pki/sa.key
      --service-cluster-ip-range=10.96.0.0/12
      --use-service-account-credentials=true
    State:          Waiting
      Reason:       CrashLoopBackOff
    Last State:     Terminated
      Reason:       Error
      Exit Code:    1
      Started:      Mon, 20 May 2024 05:03:30 +0000
      Finished:     Mon, 20 May 2024 05:03:31 +0000
    Ready:          False
    Restart Count:  4
    Requests:
      cpu:        200m
    Liveness:     http-get https://127.0.0.1:10257/healthz delay=10s timeout=15s period=10s #success=1 #failure=8
    Startup:      http-get https://127.0.0.1:10257/healthz delay=10s timeout=15s period=10s #success=1 #failure=24
    Environment:  <none>
    Mounts:
      /etc/ca-certificates from etc-ca-certificates (ro)
      /etc/kubernetes/controller-manager.conf from kubeconfig (ro)
      /etc/kubernetes/pki from k8s-certs (ro)
      /etc/ssl/certs from ca-certs (ro)
      /usr/libexec/kubernetes/kubelet-plugins/volume/exec from flexvolume-dir (rw)
      /usr/local/share/ca-certificates from usr-local-share-ca-certificates (ro)
      /usr/share/ca-certificates from usr-share-ca-certificates (ro)
Conditions:
  Type                        Status
  PodReadyToStartContainers   True 
  Initialized                 True 
  Ready                       False 
  ContainersReady             False 
  PodScheduled                True 
Volumes:
  ca-certs:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/ssl/certs
    HostPathType:  DirectoryOrCreate
  etc-ca-certificates:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/ca-certificates
    HostPathType:  DirectoryOrCreate
  flexvolume-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /usr/libexec/kubernetes/kubelet-plugins/volume/exec
    HostPathType:  DirectoryOrCreate
  k8s-certs:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/kubernetes/WRONG-PKI-DIRECTORY
    HostPathType:  DirectoryOrCreate
  kubeconfig:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/kubernetes/controller-manager.conf
    HostPathType:  FileOrCreate
  usr-local-share-ca-certificates:
    Type:          HostPath (bare host directory volume)
    Path:          /usr/local/share/ca-certificates
    HostPathType:  DirectoryOrCreate
  usr-share-ca-certificates:
    Type:          HostPath (bare host directory volume)
    Path:          /usr/share/ca-certificates
    HostPathType:  DirectoryOrCreate
QoS Class:         Burstable
Node-Selectors:    <none>
Tolerations:       :NoExecute op=Exists
Events:
  Type     Reason   Age                   From     Message
  ----     ------   ----                  ----     -------
  Normal   Pulled   65s (x5 over 2m32s)   kubelet  Container image "registry.k8s.io/kube-controller-manager:v1.29.0" already present on machine
  Normal   Created  65s (x5 over 2m32s)   kubelet  Created container kube-controller-manager
  Normal   Started  65s (x5 over 2m31s)   kubelet  Started container kube-controller-manager
  Warning  BackOff  62s (x10 over 2m27s)  kubelet  Back-off restarting failed container kube-controller-manager in pod kube-controller-manager-controlplane_kube-system(f3acd5d8bac629a5bb29ac545fabcc86)

controlplane ~ ➜  k -n kube-system log pod kube-controller-manager-controlplane 
Error: flags cannot be placed before plugin name: -n

controlplane ~ ✖ k -n kube-system log kube-controller-manager-controlplane 
Error: flags cannot be placed before plugin name: -n

controlplane ~ ✖ k log kube-controller-manager-controlplane 
error: unknown command "log" for "kubectl"

Did you mean this?
        top
        logs

controlplane ~ ✖ k logs kube-controller-manager-controlplane 
Error from server (NotFound): pods "kube-controller-manager-controlplane" not found

controlplane ~ ✖ k logs kube-controller-manager-controlplane -n kube-system 
I0520 05:05:06.529700       1 serving.go:380] Generated self-signed cert in-memory
E0520 05:05:06.917938       1 run.go:74] "command failed" err="unable to load client CA provider: open /etc/kubernetes/pki/ca.crt: no such file or directory"

controlplane ~ ➜  cd /etc/kubernetes/

controlplane /etc/kubernetes ➜  ls
admin.conf               kubelet.conf  pki             super-admin.conf
controller-manager.conf  manifests     scheduler.conf  WRONG-PKI-DIRECTORY

controlplane /etc/kubernetes ➜  cd pki/

controlplane /etc/kubernetes/pki ➜  ls
apiserver.crt                 apiserver-kubelet-client.key  front-proxy-ca.key
apiserver-etcd-client.crt     ca.crt                        front-proxy-client.crt
apiserver-etcd-client.key     ca.key                        front-proxy-client.key
apiserver.key                 etcd                          sa.key
apiserver-kubelet-client.crt  front-proxy-ca.crt            sa.pub

controlplane /etc/kubernetes/pki ➜  cd 

controlplane ~ ➜  cd /etc/kubernetes/

controlplane /etc/kubernetes ➜  cat controller-manager.conf 
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURCVENDQWUyZ0F3SUJBZ0lJYTRFRXBHRlAzUE13RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5TkRBMU1qQXdOREE1TWpaYUZ3MHpOREExTVRnd05ERTBNalphTUJVeApFekFSQmdOVkJBTVRDbXQxWW1WeWJtVjBaWE13Z2dFaU1BMEdDU3FHU0liM0RRRUJBUVVBQTRJQkR3QXdnZ0VLCkFvSUJBUUN5bXV5OVpLR0hjbStnK0ZFd2RoWjduelMrTGRMd1NUUE1IZytXbnkzbUNhRTlod01kbnV6UG5UeXcKU3RCOG5ndTVoOHkzTnNENVJrUmhGR2daSnl5Tkg4M3R5Q3ZpMWNnZUVJRVo4V1AzbERMWnhDRW5UOThUSkxvMApDVnpleDZmYzF5V2NuQmJmQXBFUDZaNDFXc1hHM3Q4L0lBLzgwN3NBVERENnFkRFAzbnZpNVNoTjMyNlQwUndOCjBIc2xjY2VUOWFFOENmNFYyUWp4QjE0bEpKN21qREkwaDZMai83MTZ0TWVQNHhnQWp6MDJHKzM5QkxvWGlWMFEKR0g1cExieitjZCt2R3Ayb2Q5a1BpRmJvM1J5UTAyN3lnZDY3YTFEdElwS2JQalYyZWhzYmVZcVlhNENsRWtjVQpLOURSVTM4ZmZqcVBua055T1d5UEZ2YUFLN1Z2QWdNQkFBR2pXVEJYTUE0R0ExVWREd0VCL3dRRUF3SUNwREFQCkJnTlZIUk1CQWY4RUJUQURBUUgvTUIwR0ExVWREZ1FXQkJTYlVZc1I3a25UTGg2c05TNzR5bkpYdGJ3b3BUQVYKQmdOVkhSRUVEakFNZ2dwcmRXSmxjbTVsZEdWek1BMEdDU3FHU0liM0RRRUJDd1VBQTRJQkFRQUxRay9pa2Y4SQpaNmF3NnJJWThKZnMxMEYwSUtzL2RpL1F3QWhaaWMxQ0pOVTZFNUNlcHNSQm41ZXlYL1B6RE9vOE1pMXdtdklSCmluMGk5NEFKR0s2S0F5U3FhRVVYWEZZclRncElLSEhOL2dtU3RxZURnQ1hSOTE4dlB5ZWptOEp4VGk3ZjJjRjUKRUY2Tk41TUNhLzNuVG1Wd1pscHlqYmkySVE2bG9Jck9oY1ZKYWZSVEFHbjFaajhQVmdRcHVFVjlYTFVXbklaYgprbklWRGlPNWdPZ3FOV29VQmp3YVpERnV2T2c2NDVZaHBiUkhXWVBDR3d5RkpJZi9sMVBuU2ZyS0FQaUhBMUlOCnY1TEdvVXIxaENTWWJzUENxVjhRQ0cxUEo1VCtJUkI2SjBZZEg1dzMyRkVsSWhyc2NyeGR6dWdTT2NkUmNiV0EKVktEOEE2NktzVjZ1Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    server: https://192.5.224.6:6443
  name: kubernetes
contexts:
- context:
    cluster: kubernetes
    user: system:kube-controller-manager
  name: system:kube-controller-manager@kubernetes
current-context: system:kube-controller-manager@kubernetes
kind: Config
preferences: {}
users:
- name: system:kube-controller-manager
  user:
    client-certificate-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURGakNDQWY2Z0F3SUJBZ0lJR0dSS1RkYm5tRHN3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5TkRBMU1qQXdOREE1TWpaYUZ3MHlOVEExTWpBd05ERTBNekJhTUNreApKekFsQmdOVkJBTVRIbk41YzNSbGJUcHJkV0psTFdOdmJuUnliMnhzWlhJdGJXRnVZV2RsY2pDQ0FTSXdEUVlKCktvWklodmNOQVFFQkJRQURnZ0VQQURDQ0FRb0NnZ0VCQUtnQW1GRW9qdXlCcGJlcE1Cdk9pamhXblhrTVVVNDMKMG5uZ2RnaEwyY0VNOWoyc3g4Ynlmbjc3NWJNTVRPTWRPOG1XQVNYR2JRMWZUS243MzczRmVuSC9VSFR4MllOawpUWTdSL3ViOVZTMkVjUWF5d1ZLcERST2d4OEdZZnlpT1owWW0vNTkyQ3J4THhsQlZ1dHI0TG1HRlQ1Rm4yU0l4CjZ5b3BQMm43RWtqQW5RTzZMMFNjRHNvZzJzZ3NEKzRCQ0RFS2J6NThRSnVvdTJQTThFQTV5bWZyRGw1VkFxODUKY3V4blBJWGJLemVQSXNBS2VobnhJUmx2RGc1NkNLZFA4cmMxWDJXd3pxK1FYZElDZFR5eExXRVRUYy9KOXV5NQo4UUJCeHcyZFNWYWFKMjFLNWxPUWlQWjJQb3BMQkttdkN0cmxFSUJmK2gvOXFPSU15aEtrUFZzQ0F3RUFBYU5XCk1GUXdEZ1lEVlIwUEFRSC9CQVFEQWdXZ01CTUdBMVVkSlFRTU1Bb0dDQ3NHQVFVRkJ3TUNNQXdHQTFVZEV3RUIKL3dRQ01BQXdId1lEVlIwakJCZ3dGb0FVbTFHTEVlNUoweTRlckRVdStNcHlWN1c4S0tVd0RRWUpLb1pJaHZjTgpBUUVMQlFBRGdnRUJBRE5XdXpTeFFBang3bHprTEdIUjBGVWVzcFZHS0F1ZFdPSm02KzRTZVVuSzkxcWkzZXFECjRzV05ZYUFHNTFhcDYzTnhIZTE1aHVlQ1M3bVBsanZvQWczb0FweHFFd0xhb1lGWndZNFhnNjBab3VySmVNdzYKVTVBdHRBV2k1RldOell4aVhkdnVUZXk3ZU5tRGxFSzhVWkNrNmpxdVZlTDVDZmlCS3RGbGhicEJuelh5VVZNMApra3U5eEZtZkZhMEI3NlpkS1gzcFBFLzFORFJ2Sys2ZGxPVzh5TkNvY0k1M0VCYnZNL0c2SGVIRU51cUFQUWo0ClVGV3M3cWNMYnBILzFVdGEwY3ZweWdTWGRXQ0p0cGV5cE5VMGcyakR2RVcvdXg4eWxtRWNYSUIrREdsNVJiZWYKbWIyYmcwSjlUbDdEZnYwRlgwZmMwSWZtTDg2WWFURllDeWM9Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    client-key-data: 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

controlplane /etc/kubernetes ➜  k describe pod -n kube-system kube-controller-manager-controlplane 
Name:                 kube-controller-manager-controlplane
Namespace:            kube-system
Priority:             2000001000
Priority Class Name:  system-node-critical
Node:                 controlplane/192.5.224.6
Start Time:           Mon, 20 May 2024 04:56:03 +0000
Labels:               component=kube-controller-manager
                      tier=control-plane
Annotations:          kubernetes.io/config.hash: f3acd5d8bac629a5bb29ac545fabcc86
                      kubernetes.io/config.mirror: f3acd5d8bac629a5bb29ac545fabcc86
                      kubernetes.io/config.seen: 2024-05-20T05:01:50.817835092Z
                      kubernetes.io/config.source: file
Status:               Running
SeccompProfile:       RuntimeDefault
IP:                   192.5.224.6
IPs:
  IP:           192.5.224.6
Controlled By:  Node/controlplane
Containers:
  kube-controller-manager:
    Container ID:  containerd://d112c225e1997f56fb0696e300848f4da37b73775a2d2568d6372a078c55b8bb
    Image:         registry.k8s.io/kube-controller-manager:v1.29.0
    Image ID:      registry.k8s.io/kube-controller-manager@sha256:d1e38ea25b27e57b41995ef59ad76dd33481853a5b8d1a91abb7a8be32b7e7da
    Port:          <none>
    Host Port:     <none>
    Command:
      kube-controller-manager
      --allocate-node-cidrs=true
      --authentication-kubeconfig=/etc/kubernetes/controller-manager.conf
      --authorization-kubeconfig=/etc/kubernetes/controller-manager.conf
      --bind-address=127.0.0.1
      --client-ca-file=/etc/kubernetes/pki/ca.crt
      --cluster-cidr=10.244.0.0/16
      --cluster-name=kubernetes
      --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt
      --cluster-signing-key-file=/etc/kubernetes/pki/ca.key
      --controllers=*,bootstrapsigner,tokencleaner
      --kubeconfig=/etc/kubernetes/controller-manager.conf
      --leader-elect=true
      --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
      --root-ca-file=/etc/kubernetes/pki/ca.crt
      --service-account-private-key-file=/etc/kubernetes/pki/sa.key
      --service-cluster-ip-range=10.96.0.0/12
      --use-service-account-credentials=true
    State:          Waiting
      Reason:       CrashLoopBackOff
    Last State:     Terminated
      Reason:       Error
      Exit Code:    1
      Started:      Mon, 20 May 2024 05:07:57 +0000
      Finished:     Mon, 20 May 2024 05:07:58 +0000
    Ready:          False
    Restart Count:  6
    Requests:
      cpu:        200m
    Liveness:     http-get https://127.0.0.1:10257/healthz delay=10s timeout=15s period=10s #success=1 #failure=8
    Startup:      http-get https://127.0.0.1:10257/healthz delay=10s timeout=15s period=10s #success=1 #failure=24
    Environment:  <none>
    Mounts:
      /etc/ca-certificates from etc-ca-certificates (ro)
      /etc/kubernetes/controller-manager.conf from kubeconfig (ro)
      /etc/kubernetes/pki from k8s-certs (ro)
      /etc/ssl/certs from ca-certs (ro)
      /usr/libexec/kubernetes/kubelet-plugins/volume/exec from flexvolume-dir (rw)
      /usr/local/share/ca-certificates from usr-local-share-ca-certificates (ro)
      /usr/share/ca-certificates from usr-share-ca-certificates (ro)
Conditions:
  Type                        Status
  PodReadyToStartContainers   True 
  Initialized                 True 
  Ready                       False 
  ContainersReady             False 
  PodScheduled                True 
Volumes:
  ca-certs:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/ssl/certs
    HostPathType:  DirectoryOrCreate
  etc-ca-certificates:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/ca-certificates
    HostPathType:  DirectoryOrCreate
  flexvolume-dir:
    Type:          HostPath (bare host directory volume)
    Path:          /usr/libexec/kubernetes/kubelet-plugins/volume/exec
    HostPathType:  DirectoryOrCreate
  k8s-certs:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/kubernetes/WRONG-PKI-DIRECTORY
    HostPathType:  DirectoryOrCreate
  kubeconfig:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/kubernetes/controller-manager.conf
    HostPathType:  FileOrCreate
  usr-local-share-ca-certificates:
    Type:          HostPath (bare host directory volume)
    Path:          /usr/local/share/ca-certificates
    HostPathType:  DirectoryOrCreate
  usr-share-ca-certificates:
    Type:          HostPath (bare host directory volume)
    Path:          /usr/share/ca-certificates
    HostPathType:  DirectoryOrCreate
QoS Class:         Burstable
Node-Selectors:    <none>
Tolerations:       :NoExecute op=Exists
Events:
  Type     Reason   Age                   From     Message
  ----     ------   ----                  ----     -------
  Normal   Pulled   6m42s (x5 over 8m9s)  kubelet  Container image "registry.k8s.io/kube-controller-manager:v1.29.0" already present on machine
  Normal   Created  6m42s (x5 over 8m9s)  kubelet  Created container kube-controller-manager
  Normal   Started  6m42s (x5 over 8m8s)  kubelet  Started container kube-controller-manager
  Warning  BackOff  3m8s (x28 over 8m4s)  kubelet  Back-off restarting failed container kube-controller-manager in pod kube-controller-manager-controlplane_kube-system(f3acd5d8bac629a5bb29ac545fabcc86)

controlplane /etc/kubernetes ➜  k logs kube-controller-manager-controlplane -n kube-system 
I0520 05:07:58.235205       1 serving.go:380] Generated self-signed cert in-memory
E0520 05:07:58.451669       1 run.go:74] "command failed" err="unable to load client CA provider: open /etc/kubernetes/pki/ca.crt: no such file or directory"

controlplane /etc/kubernetes ➜  k get all -n kube-system 
NAME                                       READY   STATUS             RESTARTS     AGE
pod/coredns-69f9c977-88s47                 1/1     Running            0            58m
pod/coredns-69f9c977-vkp8z                 1/1     Running            0            58m
pod/etcd-controlplane                      1/1     Running            0            58m
pod/kube-apiserver-controlplane            1/1     Running            0            58m
pod/kube-controller-manager-controlplane   0/1     CrashLoopBackOff   7 (7s ago)   11m
pod/kube-proxy-6lnm2                       1/1     Running            0            58m
pod/kube-scheduler-controlplane            1/1     Running            0            43m

NAME               TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                  AGE
service/kube-dns   ClusterIP   10.96.0.10   <none>        53/UDP,53/TCP,9153/TCP   58m

NAME                        DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
daemonset.apps/kube-proxy   1         1         1       1            1           kubernetes.io/os=linux   58m

NAME                      READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/coredns   2/2     2            2           58m

NAME                               DESIRED   CURRENT   READY   AGE
replicaset.apps/coredns-69f9c977   2         2         2       58m

controlplane /etc/kubernetes ➜  k get all
NAME                       READY   STATUS    RESTARTS   AGE
pod/app-5646649cc9-df2f9   1/1     Running   0          16m
pod/app-5646649cc9-t7h8x   1/1     Running   0          47m

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   58m

NAME                  READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/app   2/3     2            2           47m

NAME                             DESIRED   CURRENT   READY   AGE
replicaset.apps/app-5646649cc9   2         2         2       47m

controlplane /etc/kubernetes ➜  k edit pod -n kube-system kube-controller-manager-controlpl
ane 
error: pods "kube-controller-manager-controlplane" is invalid
A copy of your changes has been stored to "/tmp/kubectl-edit-1784551998.yaml"
error: Edit cancelled, no valid changes were saved.

controlplane /etc/kubernetes ✖ ls
admin.conf               kubelet.conf  pki             super-admin.conf
controller-manager.conf  manifests     scheduler.conf  WRONG-PKI-DIRECTORY

controlplane /etc/kubernetes ➜  cd manifests/

controlplane /etc/kubernetes/manifests ➜  ls
etcd.yaml  kube-apiserver.yaml  kube-controller-manager.yaml  kube-scheduler.yaml

controlplane /etc/kubernetes/manifests ➜  cat kube-controller-manager.yaml 
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    component: kube-controller-manager
    tier: control-plane
  name: kube-controller-manager
  namespace: kube-system
spec:
  containers:
  - command:
    - kube-controller-manager
    - --allocate-node-cidrs=true
    - --authentication-kubeconfig=/etc/kubernetes/controller-manager.conf
    - --authorization-kubeconfig=/etc/kubernetes/controller-manager.conf
    - --bind-address=127.0.0.1
    - --client-ca-file=/etc/kubernetes/pki/ca.crt
    - --cluster-cidr=10.244.0.0/16
    - --cluster-name=kubernetes
    - --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt
    - --cluster-signing-key-file=/etc/kubernetes/pki/ca.key
    - --controllers=*,bootstrapsigner,tokencleaner
    - --kubeconfig=/etc/kubernetes/controller-manager.conf
    - --leader-elect=true
    - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
    - --root-ca-file=/etc/kubernetes/pki/ca.crt
    - --service-account-private-key-file=/etc/kubernetes/pki/sa.key
    - --service-cluster-ip-range=10.96.0.0/12
    - --use-service-account-credentials=true
    image: registry.k8s.io/kube-controller-manager:v1.29.0
    imagePullPolicy: IfNotPresent
    livenessProbe:
      failureThreshold: 8
      httpGet:
        host: 127.0.0.1
        path: /healthz
        port: 10257
        scheme: HTTPS
      initialDelaySeconds: 10
      periodSeconds: 10
      timeoutSeconds: 15
    name: kube-controller-manager
    resources:
      requests:
        cpu: 200m
    startupProbe:
      failureThreshold: 24
      httpGet:
        host: 127.0.0.1
        path: /healthz
        port: 10257
        scheme: HTTPS
      initialDelaySeconds: 10
      periodSeconds: 10
      timeoutSeconds: 15
    volumeMounts:
    - mountPath: /etc/ssl/certs
      name: ca-certs
      readOnly: true
    - mountPath: /etc/ca-certificates
      name: etc-ca-certificates
      readOnly: true
    - mountPath: /usr/libexec/kubernetes/kubelet-plugins/volume/exec
      name: flexvolume-dir
    - mountPath: /etc/kubernetes/pki
      name: k8s-certs
      readOnly: true
    - mountPath: /etc/kubernetes/controller-manager.conf
      name: kubeconfig
      readOnly: true
    - mountPath: /usr/local/share/ca-certificates
      name: usr-local-share-ca-certificates
      readOnly: true
    - mountPath: /usr/share/ca-certificates
      name: usr-share-ca-certificates
      readOnly: true
  hostNetwork: true
  priority: 2000001000
  priorityClassName: system-node-critical
  securityContext:
    seccompProfile:
      type: RuntimeDefault
  volumes:
  - hostPath:
      path: /etc/ssl/certs
      type: DirectoryOrCreate
    name: ca-certs
  - hostPath:
      path: /etc/ca-certificates
      type: DirectoryOrCreate
    name: etc-ca-certificates
  - hostPath:
      path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec
      type: DirectoryOrCreate
    name: flexvolume-dir
  - hostPath:
      path: /etc/kubernetes/WRONG-PKI-DIRECTORY
      type: DirectoryOrCreate
    name: k8s-certs
  - hostPath:
      path: /etc/kubernetes/controller-manager.conf
      type: FileOrCreate
    name: kubeconfig
  - hostPath:
      path: /usr/local/share/ca-certificates
      type: DirectoryOrCreate
    name: usr-local-share-ca-certificates
  - hostPath:
      path: /usr/share/ca-certificates
      type: DirectoryOrCreate
    name: usr-share-ca-certificates
status: {}

controlplane /etc/kubernetes/manifests ➜  vi kube-controller-manager.yaml 

controlplane /etc/kubernetes/manifests ➜  cat kube-controller-manager.yaml 
apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    component: kube-controller-manager
    tier: control-plane
  name: kube-controller-manager
  namespace: kube-system
spec:
  containers:
  - command:
    - kube-controller-manager
    - --allocate-node-cidrs=true
    - --authentication-kubeconfig=/etc/kubernetes/controller-manager.conf
    - --authorization-kubeconfig=/etc/kubernetes/controller-manager.conf
    - --bind-address=127.0.0.1
    - --client-ca-file=/etc/kubernetes/pki/ca.crt
    - --cluster-cidr=10.244.0.0/16
    - --cluster-name=kubernetes
    - --cluster-signing-cert-file=/etc/kubernetes/pki/ca.crt
    - --cluster-signing-key-file=/etc/kubernetes/pki/ca.key
    - --controllers=*,bootstrapsigner,tokencleaner
    - --kubeconfig=/etc/kubernetes/controller-manager.conf
    - --leader-elect=true
    - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt
    - --root-ca-file=/etc/kubernetes/pki/ca.crt
    - --service-account-private-key-file=/etc/kubernetes/pki/sa.key
    - --service-cluster-ip-range=10.96.0.0/12
    - --use-service-account-credentials=true
    image: registry.k8s.io/kube-controller-manager:v1.29.0
    imagePullPolicy: IfNotPresent
    livenessProbe:
      failureThreshold: 8
      httpGet:
        host: 127.0.0.1
        path: /healthz
        port: 10257
        scheme: HTTPS
      initialDelaySeconds: 10
      periodSeconds: 10
      timeoutSeconds: 15
    name: kube-controller-manager
    resources:
      requests:
        cpu: 200m
    startupProbe:
      failureThreshold: 24
      httpGet:
        host: 127.0.0.1
        path: /healthz
        port: 10257
        scheme: HTTPS
      initialDelaySeconds: 10
      periodSeconds: 10
      timeoutSeconds: 15
    volumeMounts:
    - mountPath: /etc/ssl/certs
      name: ca-certs
      readOnly: true
    - mountPath: /etc/ca-certificates
      name: etc-ca-certificates
      readOnly: true
    - mountPath: /usr/libexec/kubernetes/kubelet-plugins/volume/exec
      name: flexvolume-dir
    - mountPath: /etc/kubernetes/pki
      name: k8s-certs
      readOnly: true
    - mountPath: /etc/kubernetes/controller-manager.conf
      name: kubeconfig
      readOnly: true
    - mountPath: /usr/local/share/ca-certificates
      name: usr-local-share-ca-certificates
      readOnly: true
    - mountPath: /usr/share/ca-certificates
      name: usr-share-ca-certificates
      readOnly: true
  hostNetwork: true
  priority: 2000001000
  priorityClassName: system-node-critical
  securityContext:
    seccompProfile:
      type: RuntimeDefault
  volumes:
  - hostPath:
      path: /etc/ssl/certs
      type: DirectoryOrCreate
    name: ca-certs
  - hostPath:
      path: /etc/ca-certificates
      type: DirectoryOrCreate
    name: etc-ca-certificates
  - hostPath:
      path: /usr/libexec/kubernetes/kubelet-plugins/volume/exec
      type: DirectoryOrCreate
    name: flexvolume-dir
  - hostPath:
      path: /etc/kubernetes/pki
      type: DirectoryOrCreate
    name: k8s-certs
  - hostPath:
      path: /etc/kubernetes/controller-manager.conf
      type: FileOrCreate
    name: kubeconfig
  - hostPath:
      path: /usr/local/share/ca-certificates
      type: DirectoryOrCreate
    name: usr-local-share-ca-certificates
  - hostPath:
      path: /usr/share/ca-certificates
      type: DirectoryOrCreate
    name: usr-share-ca-certificates
status: {}

controlplane /etc/kubernetes/manifests ➜  k get all
NAME                       READY   STATUS    RESTARTS   AGE
pod/app-5646649cc9-df2f9   1/1     Running   0          21m
pod/app-5646649cc9-t7h8x   1/1     Running   0          51m

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   63m

NAME                  READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/app   2/3     2            2           51m

NAME                             DESIRED   CURRENT   READY   AGE
replicaset.apps/app-5646649cc9   2         2         2       51m

controlplane /etc/kubernetes/manifests ➜  k get all -n kube-system 
NAME                                       READY   STATUS    RESTARTS   AGE
pod/coredns-69f9c977-88s47                 1/1     Running   0          63m
pod/coredns-69f9c977-vkp8z                 1/1     Running   0          63m
pod/etcd-controlplane                      1/1     Running   0          63m
pod/kube-apiserver-controlplane            1/1     Running   0          63m
pod/kube-controller-manager-controlplane   0/1     Running   0          20s
pod/kube-proxy-6lnm2                       1/1     Running   0          63m
pod/kube-scheduler-controlplane            1/1     Running   0          48m

NAME               TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                  AGE
service/kube-dns   ClusterIP   10.96.0.10   <none>        53/UDP,53/TCP,9153/TCP   63m

NAME                        DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
daemonset.apps/kube-proxy   1         1         1       1            1           kubernetes.io/os=linux   63m

NAME                      READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/coredns   2/2     2            2           63m

NAME                               DESIRED   CURRENT   READY   AGE
replicaset.apps/coredns-69f9c977   2         2         2       63m

controlplane /etc/kubernetes/manifests ➜  k get all -n kube-system 
NAME                                       READY   STATUS    RESTARTS   AGE
pod/coredns-69f9c977-88s47                 1/1     Running   0          63m
pod/coredns-69f9c977-vkp8z                 1/1     Running   0          63m
pod/etcd-controlplane                      1/1     Running   0          63m
pod/kube-apiserver-controlplane            1/1     Running   0          63m
pod/kube-controller-manager-controlplane   1/1     Running   0          43s
pod/kube-proxy-6lnm2                       1/1     Running   0          63m
pod/kube-scheduler-controlplane            1/1     Running   0          48m

NAME               TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)                  AGE
service/kube-dns   ClusterIP   10.96.0.10   <none>        53/UDP,53/TCP,9153/TCP   63m

NAME                        DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
daemonset.apps/kube-proxy   1         1         1       1            1           kubernetes.io/os=linux   63m

NAME                      READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/coredns   2/2     2            2           63m

NAME                               DESIRED   CURRENT   READY   AGE
replicaset.apps/coredns-69f9c977   2         2         2       63m

controlplane /etc/kubernetes/manifests ➜  k get all
NAME                       READY   STATUS    RESTARTS   AGE
pod/app-5646649cc9-df2f9   1/1     Running   0          22m
pod/app-5646649cc9-ghd7z   1/1     Running   0          19s
pod/app-5646649cc9-t7h8x   1/1     Running   0          52m

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   63m

NAME                  READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/app   3/3     3            3           52m

NAME                             DESIRED   CURRENT   READY   AGE
replicaset.apps/app-5646649cc9   3         3         3       52m

controlplane /etc/kubernetes/manifests ➜

````
