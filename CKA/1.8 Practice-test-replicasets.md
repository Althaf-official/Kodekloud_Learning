### How many PODs exist on the system?

### How many ReplicaSets exist on the system?
### How about now? How many ReplicaSets do you see?


![image](https://github.com/Althaf-official/Kodekloud_Learning/assets/105126131/a9e8714b-8309-4142-9a2c-ca0afe73ffd5)


### How many PODs are DESIRED in the new-replica-set?

Run the command: kubectl get replicaset and look at the count under the ```Desired``` column.

### What is the image used to create the pods in the new-replica-set?

![image](https://github.com/Althaf-official/Kodekloud_Learning/assets/105126131/ec3433ab-ecbd-42e8-9541-e1c686da27fb)


### How many PODs are READY in the new-replica-set?


Run the command: kubectl get replicaset and look at the count under the Ready column.

![image](https://github.com/Althaf-official/Kodekloud_Learning/assets/105126131/632d8085-b4fd-4ca5-bca4-a7121867b4e5)

### Why do you think the PODs are not ready?

```ruby
controlplane ~ ➜  kubectl get pod
NAME                    READY   STATUS             RESTARTS   AGE
new-replica-set-hcqps   0/1     ImagePullBackOff   0          4m29s
new-replica-set-2pfww   0/1     ImagePullBackOff   0          4m29s
new-replica-set-l4j2k   0/1     ImagePullBackOff   0          4m29s
new-replica-set-c726l   0/1     ImagePullBackOff   0          4m29s

controlplane ~ ➜  kubectl describe pod new-replica-set-hcqps 
Name:             new-replica-set-hcqps
Namespace:        default
Priority:         0
Service Account:  default
Node:             controlplane/192.10.88.6
Start Time:       Wed, 31 Jan 2024 05:23:57 +0000
Labels:           name=busybox-pod
Annotations:      <none>
Status:           Pending
IP:               10.42.0.9
IPs:
  IP:           10.42.0.9
Controlled By:  ReplicaSet/new-replica-set
Containers:
  busybox-container:
    Container ID:  
    Image:         busybox777
    Image ID:      
    Port:          <none>
    Host Port:     <none>
    Command:
      sh
      -c
      echo Hello Kubernetes! && sleep 3600
    State:          Waiting
      Reason:       ImagePullBackOff
    Ready:          False
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-tp4ps (ro)
Conditions:
  Type              Status
  Initialized       True 
  Ready             False 
  ContainersReady   False 
  PodScheduled      True 
Volumes:
  kube-api-access-tp4ps:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              <none>
Tolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type     Reason     Age                    From               Message
  ----     ------     ----                   ----               -------
  Normal   Scheduled  6m17s                  default-scheduler  Successfully assigned default/new-replica-set-hcqps to controlplane
  Normal   Pulling    4m47s (x4 over 6m16s)  kubelet            Pulling image "busybox777"
  Warning  Failed     4m46s (x4 over 6m16s)  kubelet            Failed to pull image "busybox777": rpc error: code = Unknown desc = failed to pull and unpack image "docker.io/library/busybox777:latest": failed to resolve reference "docker.io/library/busybox777:latest": pull access denied, repository does not exist or may require authorization: server message: insufficient_scope: authorization failed
  Warning  Failed     4m46s (x4 over 6m16s)  kubelet            Error: ErrImagePull
  Warning  Failed     4m32s (x6 over 6m16s)  kubelet            Error: ImagePullBackOff
  Normal   BackOff    74s (x20 over 6m16s)   kubelet            Back-off pulling image "busybox777"

controlplane ~ ➜  
```

### Delete any one of the 4 PODs.

### How many PODs exist now?

```ruby
controlplane ~ ➜  kubectl get pod
NAME                    READY   STATUS             RESTARTS   AGE
new-replica-set-l4j2k   0/1     ImagePullBackOff   0          8m24s
new-replica-set-2pfww   0/1     ImagePullBackOff   0          8m24s
new-replica-set-c726l   0/1     ImagePullBackOff   0          8m24s
new-replica-set-nb498   0/1     ErrImagePull       0          4s
controlplane ~ ➜  kubectl delete pod new-replica-set-l4j2k 
pod "new-replica-set-l4j2k" deleted
controlplane ~ ➜  kubectl get pod
NAME                    READY   STATUS             RESTARTS   AGE
new-replica-set-2pfww   0/1     ImagePullBackOff   0          8m44s
new-replica-set-c726l   0/1     ImagePullBackOff   0          8m44s
new-replica-set-nb498   0/1     ImagePullBackOff   0          24s
new-replica-set-mqdrj   0/1     ErrImagePull       0          4s

controlplane ~ ➜  
```
### Why are there still 4 PODs, even after you deleted one?


    ReplicaSet ensures that desired number of PODs always run

### Create a ReplicaSet using the replicaset-definition-1.yaml file located at /root/.


There is an issue with the file, so try to fix it.



Run the command: You can check for apiVersion of replicaset by command ```kubectl api-resources | grep replicaset```

```kubectl explain replicaset | grep VERSION``` and correct the apiVersion for ReplicaSet.

Then run the command: ```kubectl create -f /root/replicaset-definition-1.yaml```


```ruby
controlplane ~ ✖ cat replicaset-definition-1.yaml 
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: replicaset-1
spec:
  replicas: 2
  selector:
    matchLabels:
      tier: frontend
  template:
    metadata:
      labels:
        tier: frontend
    spec:
      containers:
      - name: nginx
        image: nginx


controlplane ~ ➜  kubectl get pod
NAME                    READY   STATUS             RESTARTS   AGE
new-replica-set-mqdrj   0/1     ImagePullBackOff   0          10m
new-replica-set-2pfww   0/1     ImagePullBackOff   0          19m
new-replica-set-c726l   0/1     ImagePullBackOff   0          19m
new-replica-set-nb498   0/1     ErrImagePull       0          11m

controlplane ~ ➜  kubectl get rs
NAME              DESIRED   CURRENT   READY   AGE
new-replica-set   4         4         0       19m

controlplane ~ ➜  kubectl create -f replicaset-definition-1.yaml 
replicaset.apps/replicaset-1 created

controlplane ~ ➜  kubectl get rs
NAME              DESIRED   CURRENT   READY   AGE
new-replica-set   4         4         0       20m
replicaset-1      2         2         0       5s

controlplane ~ ➜  kubectl get pod
NAME                    READY   STATUS              RESTARTS   AGE
new-replica-set-2pfww   0/1     ImagePullBackOff    0          20m
new-replica-set-c726l   0/1     ImagePullBackOff    0          20m
new-replica-set-nb498   0/1     ImagePullBackOff    0          11m
replicaset-1-nglrh      0/1     ContainerCreating   0          9s
replicaset-1-2qqz9      0/1     ContainerCreating   0          9s
new-replica-set-mqdrj   0/1     ImagePullBackOff    0          11m
controlplane ~ ➜  kubectl get pod
NAME                    READY   STATUS             RESTARTS   AGE
new-replica-set-nb498   0/1     ImagePullBackOff   0          13m
new-replica-set-mqdrj   0/1     ImagePullBackOff   0          13m
replicaset-1-nglrh      1/1     Running            0          99s
replicaset-1-2qqz9      1/1     Running            0          99s
new-replica-set-2pfww   0/1     ImagePullBackOff   0          21m
new-replica-set-c726l   0/1     ErrImagePull       0          21m
controlplane ~ ➜  kubectl get rs
NAME              DESIRED   CURRENT   READY   AGE
new-replica-set   4         4         0       21m
replicaset-1      2         2         2       103s

```

### Fix the issue in the replicaset-definition-2.yaml file and create a ReplicaSet using it.


This file is located at /root/.

The values for labels on lines 9 and 13 should match.

Update the /root/replicaset-definition-2.yaml file as follows:


    ---
    apiVersion: apps/v1
    kind: ReplicaSet
    metadata:
      name: replicaset-2
    spec:
      replicas: 2
      selector:
        matchLabels:
          tier: nginx
      template:
        metadata:
          labels:
            tier: nginx
        spec:
          containers:
          - name: nginx
            image: nginx
Then run: ```kubectl apply -f /root/replicaset-definition-2.yaml````


```ruby
controlplane ~ ➜  kubectl get pod
NAME                    READY   STATUS             RESTARTS   AGE
new-replica-set-nb498   0/1     ImagePullBackOff   0          14m
new-replica-set-mqdrj   0/1     ImagePullBackOff   0          14m
replicaset-1-nglrh      1/1     Running            0          3m
replicaset-1-2qqz9      1/1     Running            0          3m
new-replica-set-2pfww   0/1     ImagePullBackOff   0          23m
new-replica-set-c726l   0/1     ImagePullBackOff   0          23m

controlplane ~ ➜  kubectl get rs
\NAME              DESIRED   CURRENT   READY   AGE
new-replica-set   4         4         0       23m
replicaset-1      2         2         2       3m11s

controlplane ~ ➜  ls
replicaset-definition-1.yaml  replicaset-definition-2.yaml  sample.yaml

controlplane ~ ➜  cat replicaset-definition-2
cat: can't open 'replicaset-definition-2': No such file or directory

controlplane ~ ✖ cat replicaset-definition-2.yaml 
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: replicaset-2
spec:
  replicas: 2
  selector:
    matchLabels:
      tier: frontend
  template:
    metadata:
      labels:
        tier: nginx
    spec:
      containers:
      - name: nginx
        image: nginx


controlplane ~ ➜  ls
replicaset-definition-1.yaml  replicaset-definition-2.yaml  sample.yaml

controlplane ~ ➜  vi replicaset-definition-2.yaml 

controlplane ~ ➜  cat replicaset-definition-2.yaml 
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: replicaset-2
spec:
  replicas: 2
  selector:
    matchLabels:
      tier: frontend
  template:
    metadata:
      labels:
        tier: frontend
    spec:
      containers:
      - name: nginx
        image: nginx


controlplane ~ ➜  kubectl apply -f replicaset-definition-2.yaml 
replicaset.apps/replicaset-2 created

controlplane ~ ➜  kubectl get pod
NAME                    READY   STATUS             RESTARTS   AGE
replicaset-1-nglrh      1/1     Running            0          6m17s
replicaset-1-2qqz9      1/1     Running            0          6m17s
new-replica-set-c726l   0/1     ImagePullBackOff   0          26m
new-replica-set-nb498   0/1     ImagePullBackOff   0          18m
new-replica-set-mqdrj   0/1     ImagePullBackOff   0          17m
new-replica-set-2pfww   0/1     ErrImagePull       0          26m
replicaset-2-d2clk      1/1     Running            0          7s
replicaset-2-xnxr5      1/1     Running            0          7s

controlplane ~ ➜  kubectl get rs
NAME              DESIRED   CURRENT   READY   AGE
new-replica-set   4         4         0       26m
replicaset-1      2         2         2       6m26s
replicaset-2      2         2         2       16s

controlplane ~ ➜  
```
### Delete the two newly created ReplicaSets - replicaset-1 and replicaset-2

```ruby
controlplane ~ ➜  kubectl get rs
NAME              DESIRED   CURRENT   READY   AGE
new-replica-set   4         4         0       26m
replicaset-1      2         2         2       6m26s
replicaset-2      2         2         2       16s

controlplane ~ ➜  kubectl delete rs replicaset-1 replicaset-2 
replicaset.apps "replicaset-1" deleted
replicaset.apps "replicaset-2" deleted

controlplane ~ ➜  kubectl get rs
NAME              DESIRED   CURRENT   READY   AGE
new-replica-set   4         4         0       29m

controlplane ~ ➜  kubectl get pos
error: the server doesn't have a resource type "pos"

controlplane ~ ✖ kubectl get pod
NAME                    READY   STATUS             RESTARTS   AGE
new-replica-set-nb498   0/1     ImagePullBackOff   0          20m
new-replica-set-mqdrj   0/1     ImagePullBackOff   0          20m
new-replica-set-2pfww   0/1     ImagePullBackOff   0          29m
new-replica-set-c726l   0/1     ImagePullBackOff   0          29m
```

### Fix the original replica set new-replica-set to use the correct busybox image.


Either delete and recreate the ReplicaSet or Update the existing ReplicaSet and then delete all PODs, so new ones with the correct image will be created.



Run the command: ```kubectl edit replicaset new-replica-set```, modify the image name and then save the file.

Delete the previous pods to get the new ones with the correct image.

For this, run the command: ```kubectl delete po <pod-name>```


```ruby

controlplane ~ ➜  kubectl get pod
NAME                    READY   STATUS             RESTARTS   AGE
new-replica-set-2pfww   0/1     ImagePullBackOff   0          30m
new-replica-set-c726l   0/1     ImagePullBackOff   0          30m
new-replica-set-nb498   0/1     ImagePullBackOff   0          22m
new-replica-set-mqdrj   0/1     ErrImagePull       0          22m

controlplane ~ ➜  kubectl get rs
NAME              DESIRED   CURRENT   READY   AGE
new-replica-set   4         4         0       30m

controlplane ~ ➜  ls
replicaset-definition-1.yaml  replicaset-definition-2.yaml  sample.yaml

controlplane ~ ➜  kubectl edit rs new-replica-set 
replicaset.apps/new-replica-set edited

controlplane ~ ➜  kubectl get pod
NAME                    READY   STATUS             RESTARTS   AGE
new-replica-set-nb498   0/1     ImagePullBackOff   0          23m
new-replica-set-mqdrj   0/1     ImagePullBackOff   0          23m
new-replica-set-2pfww   0/1     ImagePullBackOff   0          31m
new-replica-set-c726l   0/1     ErrImagePull       0          31m

controlplane ~ ➜  kubectl delete pod new-replica-set-2pfww new-replica-set-c726l new-replica-set-nb498 new-replica-set-mqdrj
pod "new-replica-set-2pfww" deleted
pod "new-replica-set-c726l" deleted
pod "new-replica-set-nb498" deleted
pod "new-replica-set-mqdrj" deleted

controlplane ~ ➜  kubectl get pod
NAME                    READY   STATUS    RESTARTS   AGE
new-replica-set-br6nm   1/1     Running   0          7s
new-replica-set-zt84m   1/1     Running   0          7s
new-replica-set-8ff8f   1/1     Running   0          7s
new-replica-set-qxf76   1/1     Running   0          7s
```

### Scale the ReplicaSet to 5 PODs.


Use ```kubectl scale``` command or edit the replicaset using ```kubectl edit replicaset```.

Run the command: ```kubectl edit replicaset new-replica-set```, modify the replicas and then save the file OR run: ```kubectl scale rs new-replica-set --replicas=5``` to scale up to 5 PODs.



```ruby
controlplane ~ ➜  kubectl scale rs new-replica-set --replicas=5
replicaset.apps/new-replica-set scaled

controlplane ~ ➜  kubectl get pod
NAME                    READY   STATUS              RESTARTS   AGE
new-replica-set-br6nm   1/1     Running             0          3m47s
new-replica-set-zt84m   1/1     Running             0          3m47s
new-replica-set-8ff8f   1/1     Running             0          3m47s
new-replica-set-qxf76   1/1     Running             0          3m47s
new-replica-set-whdxj   0/1     ContainerCreating   0          23s
```


### Now scale the ReplicaSet down to 2 PODs.


Use the kubectl scale command or edit the replicaset using kubectl edit replicaset.



```ruby
controlplane ~ ➜  kubectl scale rs new-replica-set --replicas=2
replicaset.apps/new-replica-set scaled

controlplane ~ ➜  kubectl get pod
NAME                    READY   STATUS        RESTARTS   AGE
new-replica-set-8ff8f   1/1     Running       0          9m3s
new-replica-set-qxf76   1/1     Running       0          9m3s
new-replica-set-zt84m   1/1     Terminating   0          9m3s
new-replica-set-br6nm   1/1     Terminating   0          9m3s
new-replica-set-whdxj   1/1     Terminating   0          5m39s

controlplane ~ ➜  
```
