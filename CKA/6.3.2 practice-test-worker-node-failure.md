### Fix the broken cluster




Step1: Check the status of the nodes:

controlplane:~> kubectl get nodes
NAME           STATUS     ROLES           AGE   VERSION
controlplane   Ready      control-plane   19m   v1.27.0
node01         NotReady   <none>          19m   v1.27.0

controlplane:~> 


    Step 2: SSH to node01 and check the status of the container runtime (containerd, in this case) and the kubelet service.

   
    
----
    
    root@node01:~> systemctl status containerd
    ● containerd.service - containerd container runtime
         Loaded: loaded (/lib/systemd/system/containerd.service; enabled; vendor preset: enabled)
         Active: active (running) since Tue 2023-05-30 12:45:03 EDT; 20min ago
           Docs: https://containerd.io
       Main PID: 995 (containerd)
          Tasks: 100
         Memory: 146.8M
         CGroup: /system.slice/containerd.service
                 ├─ 995 /usr/bin/containerd

    root@node01:~>
    
    root@node01:~> systemctl status kubelet
    ● kubelet.service - kubelet: The Kubernetes Node Agent
         Loaded: loaded (/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled)
        Drop-In: /etc/systemd/system/kubelet.service.d
                 └─10-kubeadm.conf
         Active: inactive (dead) since Tue 2023-05-30 12:47:30 EDT; 18min ago
           Docs: https://kubernetes.io/docs/home/
        Process: 1978 ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS (code=exited, status=0/S>
       Main PID: 1978 (code=exited, status=0/SUCCESS)
Since the kubelet is not running, attempt to start it by running the following command:

    root@node01:~> systemctl start kubelet

    root@node01:~> systemctl status kubelet
● kubelet.service - kubelet: The Kubernetes Node Agent
         Loaded: loaded (/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled)
        Drop-In: /etc/systemd/system/kubelet.service.d
                 └─10-kubeadm.conf
         Active: active (running) since Tue 2023-05-30 13:06:47 EDT; 6s ago
           Docs: https://kubernetes.io/docs/home/
       Main PID: 4313 (kubelet)
          Tasks: 15 (limit: 77091)
         Memory: 31.4M
         CGroup: /system.slice/kubelet.service
node01 should go back to ready state now.



```ruby

controlplane ~ ➜  k get all
NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.96.0.1    <none>        443/TCP   6m55s

controlplane ~ ➜  k get  nodes
NAME           STATUS     ROLES           AGE     VERSION
controlplane   Ready      control-plane   7m4s    v1.29.0
node01         NotReady   <none>          6m18s   v1.29.0

controlplane ~ ➜  journalctl -u kubelet
May 20 10:38:21 controlplane kubelet[1194]: E0520 10:38:21.628990    1194 run.go:74] "comm>
May 20 10:38:31 controlplane kubelet[2432]: E0520 10:38:31.750939    2432 run.go:74] "comm>
May 20 10:38:37 controlplane kubelet[3083]: Flag --container-runtime-endpoint has been dep>
May 20 10:38:37 controlplane kubelet[3083]: Flag --pod-infra-container-image has been depr>
May 20 10:38:37 controlplane kubelet[3083]: I0520 10:38:37.364240    3083 server.go:204] ">
May 20 10:38:37 controlplane kubelet[3083]: I0520 10:38:37.656693    3083 server.go:487] ">
May 20 10:38:37 controlplane kubelet[3083]: I0520 10:38:37.656737    3083 server.go:489] ">
May 20 10:38:37 controlplane kubelet[3083]: I0520 10:38:37.657033    3083 server.go:919] ">
May 20 10:38:37 controlplane kubelet[3083]: E0520 10:38:37.661821    3083 certificate_mana>
May 20 10:38:37 controlplane kubelet[3083]: I0520 10:38:37.661980    3083 dynamic_cafile_c>
May 20 10:38:37 controlplane kubelet[3083]: I0520 10:38:37.736385    3083 server.go:745] ">
May 20 10:38:37 controlplane kubelet[3083]: I0520 10:38:37.745683    3083 container_manage>
May 20 10:38:37 controlplane kubelet[3083]: I0520 10:38:37.745886    3083 container_manage>
May 20 10:38:37 controlplane kubelet[3083]: I0520 10:38:37.747081    3083 topology_manager>
May 20 10:38:37 controlplane kubelet[3083]: I0520 10:38:37.747113    3083 container_manage>
May 20 10:38:37 controlplane kubelet[3083]: I0520 10:38:37.748117    3083 state_mem.go:36]>
May 20 10:38:37 controlplane kubelet[3083]: I0520 10:38:37.748243    3083 kubelet.go:396] >
May 20 10:38:37 controlplane kubelet[3083]: I0520 10:38:37.748262    3083 kubelet.go:301] >
May 20 10:38:37 controlplane kubelet[3083]: I0520 10:38:37.748288    3083 kubelet.go:312] >
May 20 10:38:37 controlplane kubelet[3083]: I0520 10:38:37.748302    3083 apiserver.go:42]>
May 20 10:38:37 controlplane kubelet[3083]: I0520 10:38:37.748949    3083 kuberuntime_mana>
May 20 10:38:37 controlplane kubelet[3083]: I0520 10:38:37.749318    3083 kubelet.go:809] >
May 20 10:38:37 controlplane kubelet[3083]: W0520 10:38:37.749386    3083 probe.go:268] Fl>
May 20 10:38:37 controlplane kubelet[3083]: W0520 10:38:37.749639    3083 reflector.go:539>
May 20 10:38:37 controlplane kubelet[3083]: E0520 10:38:37.749734    3083 reflector.go:147>
May 20 10:38:37 controlplane kubelet[3083]: W0520 10:38:37.749761    3083 reflector.go:539>
May 20 10:38:37 controlplane kubelet[3083]: E0520 10:38:37.749846    3083 reflector.go:147>
May 20 10:38:37 controlplane kubelet[3083]: I0520 10:38:37.758965    3083 server.go:1256] >
May 20 10:38:37 controlplane kubelet[3083]: I0520 10:38:37.759061    3083 server.go:162] ">
May 20 10:38:37 controlplane kubelet[3083]: I0520 10:38:37.759227    3083 ratelimit.go:55]>
lines 1-30

controlplane ~ ✖ ssh node01

node01 ~ ➜  systemctl status containerd
● containerd.service - containerd container runtime
     Loaded: loaded (/lib/systemd/system/containerd.service; enabled; vendor preset: enabl>
     Active: active (running) since Mon 2024-05-20 10:38:21 UTC; 9min ago
       Docs: https://containerd.io
   Main PID: 1174 (containerd)
      Tasks: 92
     Memory: 114.9M
     CGroup: /system.slice/containerd.service
             ├─1174 /usr/bin/containerd
             ├─2720 /usr/bin/containerd-shim-runc-v2 -namespace k8s.io -id a132d5f3165e0fe>
             ├─2721 /usr/bin/containerd-shim-runc-v2 -namespace k8s.io -id cb3ecd3c9727464>
             ├─kubepods-besteffort-pod0d08528f_4fe7_413c_9501_fc82cbee4036.slice:cri-conta>
             │ └─2974 /usr/local/bin/kube-proxy --config=/var/lib/kube-proxy/config.conf ->
             ├─kubepods-besteffort-pod0d08528f_4fe7_413c_9501_fc82cbee4036.slice:cri-conta>
             │ └─2780 /pause
             ├─kubepods-burstable-pod0ab3cefe_c9e4_49a3_b60b_7c857dbf3ec9.slice:cri-contai>
             │ └─3403 /opt/bin/flanneld --ip-masq --kube-subnet-mgr --iface=eth0
             └─kubepods-burstable-pod0ab3cefe_c9e4_49a3_b60b_7c857dbf3ec9.slice:cri-contai>
               └─2772 /pause

May 20 10:39:37 node01 containerd[1174]: time="2024-05-20T10:39:37.766352739Z" level=info >
May 20 10:39:38 node01 containerd[1174]: time="2024-05-20T10:39:38.009374633Z" level=info >
May 20 10:39:38 node01 containerd[1174]: time="2024-05-20T10:39:38.225976092Z" level=info >
May 20 10:39:38 node01 containerd[1174]: time="2024-05-20T10:39:38.226026032Z" level=warni>
May 20 10:39:38 node01 containerd[1174]: time="2024-05-20T10:39:38.226034433Z" level=info >
May 20 10:39:38 node01 containerd[1174]: time="2024-05-20T10:39:38.237606483Z" level=warni>
May 20 10:39:38 node01 containerd[1174]: time="2024-05-20T10:39:38.731892708Z" level=info >
May 20 10:39:38 node01 containerd[1174]: time="2024-05-20T10:39:38.770657623Z" level=info >
May 20 10:39:38 node01 containerd[1174]: time="2024-05-20T10:39:38.771234183Z" level=info >
May 20 10:39:39 node01 containerd[1174]: time="2024-05-20T10:39:39.026087981Z" level=info >


node01 ~ ✖ systemctl status kubelet
○ kubelet.service - kubelet: The Kubernetes Node Agent
     Loaded: loaded (/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled)
    Drop-In: /usr/lib/systemd/system/kubelet.service.d
             └─10-kubeadm.conf
     Active: inactive (dead) since Mon 2024-05-20 10:44:53 UTC; 3min 30s ago
       Docs: https://kubernetes.io/docs/
    Process: 2570 ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS>
   Main PID: 2570 (code=exited, status=0/SUCCESS)

May 20 10:39:33 node01 kubelet[2570]: I0520 10:39:33.652026    2570 reconciler_common.go:2>
May 20 10:39:33 node01 kubelet[2570]: I0520 10:39:33.652049    2570 reconciler_common.go:2>
May 20 10:39:34 node01 kubelet[2570]: I0520 10:39:34.669662    2570 kuberuntime_container_>
May 20 10:39:34 node01 kubelet[2570]: I0520 10:39:34.709771    2570 kuberuntime_container_>
May 20 10:39:35 node01 kubelet[2570]: I0520 10:39:35.935499    2570 pod_startup_latency_tr>
May 20 10:39:37 node01 kubelet[2570]: I0520 10:39:37.727337    2570 kuberuntime_container_>
May 20 10:39:38 node01 kubelet[2570]: I0520 10:39:38.069034    2570 kubelet_node_status.go>
May 20 10:39:38 node01 kubelet[2570]: I0520 10:39:38.730906    2570 kuberuntime_container_>
May 20 10:39:39 node01 kubelet[2570]: I0520 10:39:39.742700    2570 pod_startup_latency_tr>
May 20 10:44:53 node01 kubelet[2570]: I0520 10:44:53.270636    2570 dynamic_cafile_content>


node01 ~ ✖ systemctl start kubelet

node01 ~ ➜  systemctl status kubelet
● kubelet.service - kubelet: The Kubernetes Node Agent
     Loaded: loaded (/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled)
    Drop-In: /usr/lib/systemd/system/kubelet.service.d
             └─10-kubeadm.conf
     Active: active (running) since Mon 2024-05-20 10:48:47 UTC; 4s ago
       Docs: https://kubernetes.io/docs/
   Main PID: 6635 (kubelet)
      Tasks: 25 (limit: 251379)
     Memory: 37.2M
     CGroup: /system.slice/kubelet.service
             └─6635 /usr/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kube>

May 20 10:48:48 node01 kubelet[6635]: I0520 10:48:48.870245    6635 apiserver.go:52] "Watc>
May 20 10:48:48 node01 kubelet[6635]: I0520 10:48:48.872532    6635 topology_manager.go:21>
May 20 10:48:48 node01 kubelet[6635]: I0520 10:48:48.872624    6635 topology_manager.go:21>
May 20 10:48:48 node01 kubelet[6635]: I0520 10:48:48.903435    6635 desired_state_of_world>
May 20 10:48:48 node01 kubelet[6635]: I0520 10:48:48.917604    6635 reconciler_common.go:2>
May 20 10:48:48 node01 kubelet[6635]: I0520 10:48:48.917720    6635 reconciler_common.go:2>
May 20 10:48:48 node01 kubelet[6635]: I0520 10:48:48.917753    6635 reconciler_common.go:2>
May 20 10:48:48 node01 kubelet[6635]: I0520 10:48:48.917825    6635 reconciler_common.go:2>
May 20 10:48:48 node01 kubelet[6635]: I0520 10:48:48.917872    6635 reconciler_common.go:2>
May 20 10:48:48 node01 kubelet[6635]: I0520 10:48:48.918109    6635 reconciler_common.go:2>


node01 ~ ✖ exit
logout
Connection to node01 closed.

controlplane ~ ✖ k get nodes
NAME           STATUS   ROLES           AGE     VERSION
controlplane   Ready    control-plane   10m     v1.29.0
node01         Ready    <none>          9m44s   v1.29.0

controlplane ~ ➜



```


### The cluster is broken again. Investigate and fix the issue.




kubelet has stopped running on node01 again. Since this is a systemd managed system, we can check the kubelet log by running journalctl command. Here is a snippet showing the error with kubelet:


        root@node01:~# journalctl -u kubelet 
.
.
May 30 13:08:20 node01 kubelet[4554]: E0530 13:08:20.141826    4554 run.go:74] "command failed" err="failed to construct kubelet dependencies: unable to load client CA file /etc/kubernetes/pki/WRONG-CA-FILE.crt: open /etc/kubernetes/pki/WRONG-CA-FILE.crt: no such file or directory"
.
.


There appears to be a mistake path used for the CA certificate in the kubelet configuration.

This can be corrected by updating the file /var/lib/kubelet/config.yaml as follows: -
        
          x509:
            clientCAFile: /etc/kubernetes/pki/WRONG-CA-FILE.crt


Update the CA certificate file WRONG-CA-FILE.crt to ca.crt.

Once this is fixed, restart the kubelet service, (like we did in the previous question) and node01 should return back to a working state.


```ruby
controlplane ~ ➜  k get nodes
NAME           STATUS     ROLES           AGE   VERSION
controlplane   Ready      control-plane   14m   v1.29.0
node01         NotReady   <none>          13m   v1.29.0

controlplane ~ ➜  ssh node01
Last login: Mon May 20 10:47:14 2024 from 192.18.157.6

node01 ~ ➜  journalctl -u kubelet -f
May 20 10:54:18 node01 kubelet[8732]: I0520 10:54:18.249036    8732 server.go:204] "--pod-infra-container-image will not be pruned by the image garbage collector in kubelet and should also be set in the remote runtime"
May 20 10:54:18 node01 kubelet[8732]: E0520 10:54:18.250521    8732 run.go:74] "command failed" err="failed to construct kubelet dependencies: unable to load client CA file /etc/kubernetes/pki/WRONG-CA-FILE.crt: open /etc/kubernetes/pki/WRONG-CA-FILE.crt: no such file or directory"
May 20 10:54:28 node01 kubelet[8797]: Flag --container-runtime-endpoint has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 20 10:54:28 node01 kubelet[8797]: Flag --pod-infra-container-image has been deprecated, will be removed in a future release. Image garbage collector will get sandbox image information from CRI.
May 20 10:54:28 node01 kubelet[8797]: I0520 10:54:28.463250    8797 server.go:204] "--pod-infra-container-image will not be pruned by the image garbage collector in kubelet and should also be set in the remote runtime"
May 20 10:54:28 node01 kubelet[8797]: E0520 10:54:28.464746    8797 run.go:74] "command failed" err="failed to construct kubelet dependencies: unable to load client CA file /etc/kubernetes/pki/WRONG-CA-FILE.crt: open /etc/kubernetes/pki/WRONG-CA-FILE.crt: no such file or directory"
May 20 10:54:38 node01 kubelet[8867]: Flag --container-runtime-endpoint has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 20 10:54:38 node01 kubelet[8867]: Flag --pod-infra-container-image has been deprecated, will be removed in a future release. Image garbage collector will get sandbox image information from CRI.
May 20 10:54:38 node01 kubelet[8867]: I0520 10:54:38.720331    8867 server.go:204] "--pod-infra-container-image will not be pruned by the image garbage collector in kubelet and should also be set in the remote runtime"
May 20 10:54:38 node01 kubelet[8867]: E0520 10:54:38.721803    8867 run.go:74] "command failed" err="failed to construct kubelet dependencies: unable to load client CA file /etc/kubernetes/pki/WRONG-CA-FILE.crt: open /etc/kubernetes/pki/WRONG-CA-FILE.crt: no such file or directory"
May 20 10:54:48 node01 kubelet[8951]: Flag --container-runtime-endpoint has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 20 10:54:48 node01 kubelet[8951]: Flag --pod-infra-container-image has been deprecated, will be removed in a future release. Image garbage collector will get sandbox image information from CRI.
May 20 10:54:48 node01 kubelet[8951]: I0520 10:54:48.996606    8951 server.go:204] "--pod-infra-container-image will not be pruned by the image garbage collector in kubelet and should also be set in the remote runtime"
May 20 10:54:48 node01 kubelet[8951]: E0520 10:54:48.997967    8951 run.go:74] "command failed" err="failed to construct kubelet dependencies: unable to load client CA file /etc/kubernetes/pki/WRONG-CA-FILE.crt: open /etc/kubernetes/pki/WRONG-CA-FILE.crt: no such file or directory"
May 20 10:54:59 node01 kubelet[9015]: Flag --container-runtime-endpoint has been deprecated, This parameter should be set via the config file specified by the Kubelet's --config flag. See https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/ for more information.
May 20 10:54:59 node01 kubelet[9015]: Flag --pod-infra-container-image has been deprecated, will be removed in a future release. Image garbage collector will get sandbox image information from CRI.
May 20 10:54:59 node01 kubelet[9015]: I0520 10:54:59.232918    9015 server.go:204] "--pod-infra-container-image will not be pruned by the image garbage collector in kubelet and should also be set in the remote runtime"
May 20 10:54:59 node01 kubelet[9015]: E0520 10:54:59.234606    9015 run.go:74] "command failed" err="failed to construct kubelet dependencies: unable to load client CA file /etc/kubernetes/pki/WRONG-CA-FILE.crt: open /etc/kubernetes/pki/WRONG-CA-FILE.crt: no such file or directory"
^C

node01 ~ ✖ journalctl -u kubelet
May 20 10:38:21 node01 kubelet[1128]: E0520 10:38:21.104275    1128 run.go:74] "command fa>
May 20 10:38:31 node01 kubelet[1887]: E0520 10:38:31.216731    1887 run.go:74] "command fa>
May 20 10:38:41 node01 kubelet[1909]: E0520 10:38:41.454551    1909 run.go:74] "command fa>
May 20 10:38:51 node01 kubelet[1934]: E0520 10:38:51.706675    1934 run.go:74] "command fa>
May 20 10:39:01 node01 kubelet[1960]: E0520 10:39:01.988252    1960 run.go:74] "command fa>
May 20 10:39:12 node01 kubelet[1982]: E0520 10:39:12.209121    1982 run.go:74] "command fa>
May 20 10:39:22 node01 kubelet[2005]: E0520 10:39:22.465569    2005 run.go:74] "command fa>
May 20 10:39:31 node01 kubelet[2570]: Flag --container-runtime-endpoint has been deprecate>
May 20 10:39:31 node01 kubelet[2570]: Flag --pod-infra-container-image has been deprecated>
May 20 10:39:31 node01 kubelet[2570]: I0520 10:39:31.862410    2570 server.go:204] "--pod->
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.553383    2570 server.go:487] "Kubele>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.553433    2570 server.go:489] "Golang>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.553716    2570 server.go:919] "Client>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.559280    2570 dynamic_cafile_content>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.621690    2570 server.go:745] "--cgro>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.631694    2570 container_manager_linu>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.631900    2570 container_manager_linu>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.632474    2570 topology_manager.go:13>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.632487    2570 container_manager_linu>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.632592    2570 state_mem.go:36] "Init>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.632701    2570 kubelet.go:396] "Attem>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.632715    2570 kubelet.go:301] "Addin>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.632735    2570 kubelet.go:312] "Addin>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.632746    2570 apiserver.go:42] "Wait>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.633338    2570 kuberuntime_manager.go>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.634483    2570 kubelet.go:809] "Not s>
May 20 10:39:32 node01 kubelet[2570]: W0520 10:39:32.634540    2570 probe.go:268] Flexvolu>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.643612    2570 server.go:1256] "Start>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.643764    2570 server.go:162] "Starti>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.643869    2570 ratelimit.go:55] "Sett>


node01 ~ ✖ cd /etc/kubernetes/pki/

node01 /etc/kubernetes/pki ➜  ls
ca.crt

node01 /etc/kubernetes/pki ➜  cat ca.crt
-----BEGIN CERTIFICATE-----
MIIDBTCCAe2gAwIBAgIIP91ghPC/Lt8wDQYJKoZIhvcNAQELBQAwFTETMBEGA1UE
AxMKa3ViZXJuZXRlczAeFw0yNDA1MjAxMDMzMzNaFw0zNDA1MTgxMDM4MzNaMBUx
EzARBgNVBAMTCmt1YmVybmV0ZXMwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEK
AoIBAQDuG1gpYNrDojbAEXfAG6odRiUcfHT6A8TOfUdsrhCJYxn+u/NY/a3MZ4gJ
gNT8x+rU+v67QSVYncZB7lyf2Qdg04vCpDOhVKpozZhBaRe5fpYFBm3nVTyjIsBM
s1QrfqcrZZrZhghbWhb90ISHgHQCa9uulV5KJmQ1dbg/xBYQpzyLV/Xxwl7cEcID
IXyvLiWrNl0r5YKPdnhwK5N988fotNVqYVZZnUOZr/47VSRAtCe+W3aTYJ8kwFqo
+f4O6fRkW3NGM7aqa68+NUCq7vM9MXCiZx9p4OEOfEvehb0stTyR0ojwiDCqUh6C
hRZl4ZUzKnQgdnenUFcaZxmuSDyVAgMBAAGjWTBXMA4GA1UdDwEB/wQEAwICpDAP
BgNVHRMBAf8EBTADAQH/MB0GA1UdDgQWBBRE6mLugJlTlavvsp5B/Eg1RZxJGzAV
BgNVHREEDjAMggprdWJlcm5ldGVzMA0GCSqGSIb3DQEBCwUAA4IBAQCgAPFHQFcp
5lcaxgDv3hivvT7pTTKz+mWSOGBlxe7NqE93Om/aLBZx9yyGqk4ix2NAzLFtByEX
WAWyi1WTe43eogaEbbtqFTyzGDFOvtIFfQNkdt6GoJOARFzaYNcGq4kz0NoGnSlg
gBloEaebxZgvXFRrebhv8OFQzk4rYBqwx5NIzAnDfubcuelaCT+H6EOin6MyxOLn
X5fwLRxXSFvEkRHNF7Boi141fBqjRhidGa6qzVQteziEZz3tCYhnVyzVDbkeRVM3
o6h6pmw3jLLmLnrJvUayv2GgL5PXvGGPp4kH5PkE/UoTx0/fxcP+O6TqSmbUVKY/
jUFh+IT9H5gu
-----END CERTIFICATE-----

node01 /etc/kubernetes/pki ➜  cat /var/lib/kubelet/config.yaml 
apiVersion: kubelet.config.k8s.io/v1beta1
authentication:
  anonymous:
    enabled: false
  webhook:
    cacheTTL: 0s
    enabled: true
  x509:
    clientCAFile: /etc/kubernetes/pki/WRONG-CA-FILE.crt
authorization:
  mode: Webhook
  webhook:
    cacheAuthorizedTTL: 0s
    cacheUnauthorizedTTL: 0s
cgroupDriver: systemd
clusterDNS:
- 10.96.0.10
clusterDomain: cluster.local
containerRuntimeEndpoint: ""
cpuManagerReconcilePeriod: 0s
evictionPressureTransitionPeriod: 0s
fileCheckFrequency: 0s
healthzBindAddress: 127.0.0.1
healthzPort: 10248
httpCheckFrequency: 0s
imageMaximumGCAge: 0s
imageMinimumGCAge: 0s
kind: KubeletConfiguration
logging:
  flushFrequency: 0
  options:
    json:
      infoBufferSize: "0"
  verbosity: 0
memorySwap: {}
nodeStatusReportFrequency: 0s
nodeStatusUpdateFrequency: 0s
resolvConf: /run/systemd/resolve/resolv.conf
rotateCertificates: true
runtimeRequestTimeout: 0s
shutdownGracePeriod: 0s
shutdownGracePeriodCriticalPods: 0s
staticPodPath: /etc/kubernetes/manifests
streamingConnectionIdleTimeout: 0s
syncFrequency: 0s
volumeStatsAggPeriod: 0s

node01 /etc/kubernetes/pki ➜  vi /var/lib/kubelet/config.yaml 

node01 /etc/kubernetes/pki ➜  cat /var/lib/kubelet/config.yaml 
apiVersion: kubelet.config.k8s.io/v1beta1
authentication:
  anonymous:
    enabled: false
  webhook:
    cacheTTL: 0s
    enabled: true
  x509:
    clientCAFile: /etc/kubernetes/pki/ca.crt
authorization:
  mode: Webhook
  webhook:
    cacheAuthorizedTTL: 0s
    cacheUnauthorizedTTL: 0s
cgroupDriver: systemd
clusterDNS:
- 10.96.0.10
clusterDomain: cluster.local
containerRuntimeEndpoint: ""
cpuManagerReconcilePeriod: 0s
evictionPressureTransitionPeriod: 0s
fileCheckFrequency: 0s
healthzBindAddress: 127.0.0.1
healthzPort: 10248
httpCheckFrequency: 0s
imageMaximumGCAge: 0s
imageMinimumGCAge: 0s
kind: KubeletConfiguration
logging:
  flushFrequency: 0
  options:
    json:
      infoBufferSize: "0"
  verbosity: 0
memorySwap: {}
nodeStatusReportFrequency: 0s
nodeStatusUpdateFrequency: 0s
resolvConf: /run/systemd/resolve/resolv.conf
rotateCertificates: true
runtimeRequestTimeout: 0s
shutdownGracePeriod: 0s
shutdownGracePeriodCriticalPods: 0s
staticPodPath: /etc/kubernetes/manifests
streamingConnectionIdleTimeout: 0s
syncFrequency: 0s
volumeStatsAggPeriod: 0s

node01 /etc/kubernetes/pki ➜  systemctl status kubelet
● kubelet.service - kubelet: The Kubernetes Node Agent
     Loaded: loaded (/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled)
    Drop-In: /usr/lib/systemd/system/kubelet.service.d
             └─10-kubeadm.conf
     Active: active (running) since Mon 2024-05-20 11:02:56 UTC; 23s ago
       Docs: https://kubernetes.io/docs/
   Main PID: 12450 (kubelet)
      Tasks: 23 (limit: 251379)
     Memory: 36.3M
     CGroup: /system.slice/kubelet.service
             └─12450 /usr/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kub>

May 20 11:02:58 node01 kubelet[12450]: I0520 11:02:58.046553   12450 apiserver.go:52] "Wat>
May 20 11:02:58 node01 kubelet[12450]: I0520 11:02:58.048796   12450 topology_manager.go:2>
May 20 11:02:58 node01 kubelet[12450]: I0520 11:02:58.048911   12450 topology_manager.go:2>
May 20 11:02:58 node01 kubelet[12450]: I0520 11:02:58.058531   12450 desired_state_of_worl>
May 20 11:02:58 node01 kubelet[12450]: I0520 11:02:58.105303   12450 reconciler_common.go:>
May 20 11:02:58 node01 kubelet[12450]: I0520 11:02:58.105371   12450 reconciler_common.go:>
May 20 11:02:58 node01 kubelet[12450]: I0520 11:02:58.105418   12450 reconciler_common.go:>
May 20 11:02:58 node01 kubelet[12450]: I0520 11:02:58.105443   12450 reconciler_common.go:>
May 20 11:02:58 node01 kubelet[12450]: I0520 11:02:58.105464   12450 reconciler_common.go:>
May 20 11:02:58 node01 kubelet[12450]: I0520 11:02:58.105481   12450 reconciler_common.go:>


node01 /etc/kubernetes/pki ✖ exit
logout
Connection to node01 closed.

controlplane ~ ✖ k get nodes
NAME           STATUS   ROLES           AGE   VERSION
controlplane   Ready    control-plane   24m   v1.29.0
node01         Ready    <none>          24m   v1.29.0

controlplane ~ ➜  

```
# The cluster is broken again. Investigate and fix the issue.




Once again the kubelet service has stopped working. Checking the logs, we can see that this time, it is not able to reach the kube-apiserver.



        root@node01:~# journalctl -u kubelet 
        .
        .
        .
        May 30 13:43:55 node01 kubelet[8858]: E0530 13:43:55.004939    8858 reflector.go:148] vendor/k8s.io/client-go/informers/factory.go:150: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://controlplane:6553/api/v1/nodes?fieldSelector=metadata.name%3Dnode01&limit=500&resourceVersion=0": dial tcp 192.24.132.5:6553: connect: connection refused
        .
        .
        .


As we can clearly see, kubelet is trying to connect to the API server on the controlplane node on port 6553. This is incorrect.
To fix, correct the port on the kubeconfig file used by the kubelet.

        apiVersion: v1
        clusters:
        - cluster:
            certificate-authority-data:
            --REDACTED---
            server: https://controlplane:6443


Restart the kubelet service after this change.

        systemctl restart kubelet


```ruby

node01 ~ ✖ cat /etc/kubernetes/kubelet.conf 
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURCVENDQWUyZ0F3SUJBZ0lJUDkxZ2hQQy9MdDh3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5TkRBMU1qQXhNRE16TXpOYUZ3MHpOREExTVRneE1ETTRNek5hTUJVeApFekFSQmdOVkJBTVRDbXQxWW1WeWJtVjBaWE13Z2dFaU1BMEdDU3FHU0liM0RRRUJBUVVBQTRJQkR3QXdnZ0VLCkFvSUJBUUR1RzFncFlOckRvamJBRVhmQUc2b2RSaVVjZkhUNkE4VE9mVWRzcmhDSll4bit1L05ZL2EzTVo0Z0oKZ05UOHgrclUrdjY3UVNWWW5jWkI3bHlmMlFkZzA0dkNwRE9oVktwb3paaEJhUmU1ZnBZRkJtM25WVHlqSXNCTQpzMVFyZnFjclpaclpoZ2hiV2hiOTBJU0hnSFFDYTl1dWxWNUtKbVExZGJnL3hCWVFwenlMVi9YeHdsN2NFY0lECklYeXZMaVdyTmwwcjVZS1Bkbmh3SzVOOTg4Zm90TlZxWVZaWm5VT1pyLzQ3VlNSQXRDZStXM2FUWUo4a3dGcW8KK2Y0TzZmUmtXM05HTTdhcWE2OCtOVUNxN3ZNOU1YQ2laeDlwNE9FT2ZFdmVoYjBzdFR5UjBvandpRENxVWg2QwpoUlpsNFpVektuUWdkbmVuVUZjYVp4bXVTRHlWQWdNQkFBR2pXVEJYTUE0R0ExVWREd0VCL3dRRUF3SUNwREFQCkJnTlZIUk1CQWY4RUJUQURBUUgvTUIwR0ExVWREZ1FXQkJSRTZtTHVnSmxUbGF2dnNwNUIvRWcxUlp4Skd6QVYKQmdOVkhSRUVEakFNZ2dwcmRXSmxjbTVsZEdWek1BMEdDU3FHU0liM0RRRUJDd1VBQTRJQkFRQ2dBUEZIUUZjcAo1bGNheGdEdjNoaXZ2VDdwVFRLeittV1NPR0JseGU3TnFFOTNPbS9hTEJaeDl5eUdxazRpeDJOQXpMRnRCeUVYCldBV3lpMVdUZTQzZW9nYUViYnRxRlR5ekdERk92dElGZlFOa2R0NkdvSk9BUkZ6YVlOY0dxNGt6ME5vR25TbGcKZ0Jsb0VhZWJ4Wmd2WEZScmViaHY4T0ZRems0cllCcXd4NU5JekFuRGZ1YmN1ZWxhQ1QrSDZFT2luNk15eE9MbgpYNWZ3TFJ4WFNGdkVrUkhORjdCb2kxNDFmQnFqUmhpZEdhNnF6VlF0ZXppRVp6M3RDWWhuVnl6VkRia2VSVk0zCm82aDZwbXczakxMbUxuckp2VWF5djJHZ0w1UFh2R0dQcDRrSDVQa0UvVW9UeDAvZnhjUCtPNlRxU21iVVZLWS8KalVGaCtJVDlINWd1Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    server: https://controlplane:6553
  name: default-cluster
contexts:
- context:
    cluster: default-cluster
    namespace: default
    user: default-auth
  name: default-context
current-context: default-context
kind: Config
preferences: {}
users:
- name: default-auth
  user:
    client-certificate: /var/lib/kubelet/pki/kubelet-client-current.pem
    client-key: /var/lib/kubelet/pki/kubelet-client-current.pem

node01 ~ ➜  vi /etc/kubernetes/kubelet.conf 

node01 ~ ➜  cat /etc/kubernetes/kubelet.conf 
apiVersion: v1
clusters:
- cluster:
    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURCVENDQWUyZ0F3SUJBZ0lJUDkxZ2hQQy9MdDh3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5TkRBMU1qQXhNRE16TXpOYUZ3MHpOREExTVRneE1ETTRNek5hTUJVeApFekFSQmdOVkJBTVRDbXQxWW1WeWJtVjBaWE13Z2dFaU1BMEdDU3FHU0liM0RRRUJBUVVBQTRJQkR3QXdnZ0VLCkFvSUJBUUR1RzFncFlOckRvamJBRVhmQUc2b2RSaVVjZkhUNkE4VE9mVWRzcmhDSll4bit1L05ZL2EzTVo0Z0oKZ05UOHgrclUrdjY3UVNWWW5jWkI3bHlmMlFkZzA0dkNwRE9oVktwb3paaEJhUmU1ZnBZRkJtM25WVHlqSXNCTQpzMVFyZnFjclpaclpoZ2hiV2hiOTBJU0hnSFFDYTl1dWxWNUtKbVExZGJnL3hCWVFwenlMVi9YeHdsN2NFY0lECklYeXZMaVdyTmwwcjVZS1Bkbmh3SzVOOTg4Zm90TlZxWVZaWm5VT1pyLzQ3VlNSQXRDZStXM2FUWUo4a3dGcW8KK2Y0TzZmUmtXM05HTTdhcWE2OCtOVUNxN3ZNOU1YQ2laeDlwNE9FT2ZFdmVoYjBzdFR5UjBvandpRENxVWg2QwpoUlpsNFpVektuUWdkbmVuVUZjYVp4bXVTRHlWQWdNQkFBR2pXVEJYTUE0R0ExVWREd0VCL3dRRUF3SUNwREFQCkJnTlZIUk1CQWY4RUJUQURBUUgvTUIwR0ExVWREZ1FXQkJSRTZtTHVnSmxUbGF2dnNwNUIvRWcxUlp4Skd6QVYKQmdOVkhSRUVEakFNZ2dwcmRXSmxjbTVsZEdWek1BMEdDU3FHU0liM0RRRUJDd1VBQTRJQkFRQ2dBUEZIUUZjcAo1bGNheGdEdjNoaXZ2VDdwVFRLeittV1NPR0JseGU3TnFFOTNPbS9hTEJaeDl5eUdxazRpeDJOQXpMRnRCeUVYCldBV3lpMVdUZTQzZW9nYUViYnRxRlR5ekdERk92dElGZlFOa2R0NkdvSk9BUkZ6YVlOY0dxNGt6ME5vR25TbGcKZ0Jsb0VhZWJ4Wmd2WEZScmViaHY4T0ZRems0cllCcXd4NU5JekFuRGZ1YmN1ZWxhQ1QrSDZFT2luNk15eE9MbgpYNWZ3TFJ4WFNGdkVrUkhORjdCb2kxNDFmQnFqUmhpZEdhNnF6VlF0ZXppRVp6M3RDWWhuVnl6VkRia2VSVk0zCm82aDZwbXczakxMbUxuckp2VWF5djJHZ0w1UFh2R0dQcDRrSDVQa0UvVW9UeDAvZnhjUCtPNlRxU21iVVZLWS8KalVGaCtJVDlINWd1Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
    server: https://controlplane:6443
  name: default-cluster
contexts:
- context:
    cluster: default-cluster
    namespace: default
    user: default-auth
  name: default-context
current-context: default-context
kind: Config
preferences: {}
users:
- name: default-auth
  user:
    client-certificate: /var/lib/kubelet/pki/kubelet-client-current.pem
    client-key: /var/lib/kubelet/pki/kubelet-client-current.pem

node01 ~ ➜  systemctl restart kubelet

node01 ~ ➜  systemctl status kubelet
● kubelet.service - kubelet: The Kubernetes Node Agent
     Loaded: loaded (/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled)
    Drop-In: /usr/lib/systemd/system/kubelet.service.d
             └─10-kubeadm.conf
     Active: active (running) since Mon 2024-05-20 11:17:22 UTC; 14s ago
       Docs: https://kubernetes.io/docs/
   Main PID: 16944 (kubelet)
      Tasks: 21 (limit: 251379)
     Memory: 35.5M
     CGroup: /system.slice/kubelet.service
             └─16944 /usr/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-ku>

May 20 11:17:23 node01 kubelet[16944]: I0520 11:17:23.660510   16944 apiserver.go:52] "Wa>
May 20 11:17:23 node01 kubelet[16944]: I0520 11:17:23.663657   16944 topology_manager.go:>
May 20 11:17:23 node01 kubelet[16944]: I0520 11:17:23.663771   16944 topology_manager.go:>
May 20 11:17:23 node01 kubelet[16944]: I0520 11:17:23.672339   16944 desired_state_of_wor>
May 20 11:17:23 node01 kubelet[16944]: I0520 11:17:23.706872   16944 reconciler_common.go>
May 20 11:17:23 node01 kubelet[16944]: I0520 11:17:23.706924   16944 reconciler_common.go>
May 20 11:17:23 node01 kubelet[16944]: I0520 11:17:23.706941   16944 reconciler_common.go>
May 20 11:17:23 node01 kubelet[16944]: I0520 11:17:23.707171   16944 reconciler_common.go>
May 20 11:17:23 node01 kubelet[16944]: I0520 11:17:23.707325   16944 reconciler_common.go>
May 20 11:17:23 node01 kubelet[16944]: I0520 11:17:23.707463   16944 reconciler_common.go>


node01 ~ ✖ journalctl -u kubelet
May 20 10:38:21 node01 kubelet[1128]: E0520 10:38:21.104275    1128 run.go:74] "command f>
May 20 10:38:31 node01 kubelet[1887]: E0520 10:38:31.216731    1887 run.go:74] "command f>
May 20 10:38:41 node01 kubelet[1909]: E0520 10:38:41.454551    1909 run.go:74] "command f>
May 20 10:38:51 node01 kubelet[1934]: E0520 10:38:51.706675    1934 run.go:74] "command f>
May 20 10:39:01 node01 kubelet[1960]: E0520 10:39:01.988252    1960 run.go:74] "command f>
May 20 10:39:12 node01 kubelet[1982]: E0520 10:39:12.209121    1982 run.go:74] "command f>
May 20 10:39:22 node01 kubelet[2005]: E0520 10:39:22.465569    2005 run.go:74] "command f>
May 20 10:39:31 node01 kubelet[2570]: Flag --container-runtime-endpoint has been deprecat>
May 20 10:39:31 node01 kubelet[2570]: Flag --pod-infra-container-image has been deprecate>
May 20 10:39:31 node01 kubelet[2570]: I0520 10:39:31.862410    2570 server.go:204] "--pod>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.553383    2570 server.go:487] "Kubel>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.553433    2570 server.go:489] "Golan>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.553716    2570 server.go:919] "Clien>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.559280    2570 dynamic_cafile_conten>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.621690    2570 server.go:745] "--cgr>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.631694    2570 container_manager_lin>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.631900    2570 container_manager_lin>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.632474    2570 topology_manager.go:1>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.632487    2570 container_manager_lin>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.632592    2570 state_mem.go:36] "Ini>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.632701    2570 kubelet.go:396] "Atte>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.632715    2570 kubelet.go:301] "Addi>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.632735    2570 kubelet.go:312] "Addi>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.632746    2570 apiserver.go:42] "Wai>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.633338    2570 kuberuntime_manager.g>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.634483    2570 kubelet.go:809] "Not >
May 20 10:39:32 node01 kubelet[2570]: W0520 10:39:32.634540    2570 probe.go:268] Flexvol>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.643612    2570 server.go:1256] "Star>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.643764    2570 server.go:162] "Start>
May 20 10:39:32 node01 kubelet[2570]: I0520 10:39:32.643869    2570 ratelimit.go:55] "Set>
lines 1-30

node01 ~ ✖ exit 
logout
Connection to node01 closed.

controlplane ~ ✖ k get node
NAME           STATUS   ROLES           AGE   VERSION
controlplane   Ready    control-plane   41m   v1.29.0
node01         Ready    <none>          40m   v1.29.0

controlplane ~ ➜  
```







