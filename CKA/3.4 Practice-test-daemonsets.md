### How many DaemonSets are created in the cluster in all namespaces?

Check all namespaces

```ruby
controlplane ~ ➜  kubectl get daemonsets --all-namespaces 
NAMESPACE      NAME              DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
kube-flannel   kube-flannel-ds   1         1         1       1            1           <none>                   9m28s
kube-system    kube-proxy        1         1         1       1            1           kubernetes.io/os=linux   9m30s

```
### Which namespace is the ```kube-proxy``` Daemonset created in?


kubesystem

### Which of the below is a ```DaemonSet```?

kube-flannel-ds

### On how many nodes are the pods scheduled by the DaemonSet ```kube-proxy```?

```ruby
controlplane ~ ➜  kubectl describe daemonset kube-proxy --namespace=kube-system 
Name:           kube-proxy
Selector:       k8s-app=kube-proxy
Node-Selector:  kubernetes.io/os=linux
Labels:         k8s-app=kube-proxy
Annotations:    deprecated.daemonset.template.generation: 1
Desired Number of Nodes Scheduled: 1
Current Number of Nodes Scheduled: 1
Number of Nodes Scheduled with Up-to-date Pods: 1
Number of Nodes Scheduled with Available Pods: 1
Number of Nodes Misscheduled: 0
Pods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed
Pod Template:
  Labels:           k8s-app=kube-proxy
  Service Account:  kube-proxy
  Containers:
   kube-proxy:
    Image:      registry.k8s.io/kube-proxy:v1.27.0
    Port:       <none>
    Host Port:  <none>
    Command:
      /usr/local/bin/kube-proxy
      --config=/var/lib/kube-proxy/config.conf
      --hostname-override=$(NODE_NAME)
    Environment:
      NODE_NAME:   (v1:spec.nodeName)
    Mounts:
      /lib/modules from lib-modules (ro)
      /run/xtables.lock from xtables-lock (rw)
      /var/lib/kube-proxy from kube-proxy (rw)
  Volumes:
   kube-proxy:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      kube-proxy
    Optional:  false
   xtables-lock:
    Type:          HostPath (bare host directory volume)
    Path:          /run/xtables.lock
    HostPathType:  FileOrCreate
   lib-modules:
    Type:               HostPath (bare host directory volume)
    Path:               /lib/modules
    HostPathType:       
  Priority Class Name:  system-node-critical
Events:
  Type    Reason            Age   From                  Message
  ----    ------            ----  ----                  -------
  Normal  SuccessfulCreate  13m   daemonset-controller  Created pod: kube-proxy-qzlb6
```

### What is the image used by the POD deployed by the kube-flannel-ds DaemonSet?

```ruby

controlplane ~ ➜  kubectl describe daemonset kube-flannel-ds --namespace=kube-flannel
Name:           kube-flannel-ds
Selector:       app=flannel
Node-Selector:  <none>
Labels:         app=flannel
                tier=node
Annotations:    deprecated.daemonset.template.generation: 1
Desired Number of Nodes Scheduled: 1
Current Number of Nodes Scheduled: 1
Number of Nodes Scheduled with Up-to-date Pods: 1
Number of Nodes Scheduled with Available Pods: 1
Number of Nodes Misscheduled: 0
Pods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed
Pod Template:
  Labels:           app=flannel
                    tier=node
  Service Account:  flannel
  Init Containers:
   install-cni-plugin:
    Image:      docker.io/rancher/mirrored-flannelcni-flannel-cni-plugin:v1.1.0
    Port:       <none>
    Host Port:  <none>
    Command:
      cp
    Args:
      -f
      /flannel
      /opt/cni/bin/flannel
    Environment:  <none>
    Mounts:
      /opt/cni/bin from cni-plugin (rw)
   install-cni:
    Image:      docker.io/rancher/mirrored-flannelcni-flannel:v0.19.2
    Port:       <none>
    Host Port:  <none>
    Command:
      cp
    Args:
      -f
      /etc/kube-flannel/cni-conf.json
      /etc/cni/net.d/10-flannel.conflist
    Environment:  <none>
    Mounts:
      /etc/cni/net.d from cni (rw)
      /etc/kube-flannel/ from flannel-cfg (rw)
  Containers:
   kube-flannel:
    Image:      docker.io/rancher/mirrored-flannelcni-flannel:v0.19.2
    Port:       <none>
    Host Port:  <none>
    Command:
      /opt/bin/flanneld
    Args:
      --ip-masq
      --kube-subnet-mgr
      --iface=eth0
    Limits:
      cpu:     100m
      memory:  50Mi
    Requests:
      cpu:     100m
      memory:  50Mi
    Environment:
      POD_NAME:            (v1:metadata.name)
      POD_NAMESPACE:       (v1:metadata.namespace)
      EVENT_QUEUE_DEPTH:  5000
    Mounts:
      /etc/kube-flannel/ from flannel-cfg (rw)
      /run/flannel from run (rw)
      /run/xtables.lock from xtables-lock (rw)
  Volumes:
   run:
    Type:          HostPath (bare host directory volume)
    Path:          /run/flannel
    HostPathType:  
   cni-plugin:
    Type:          HostPath (bare host directory volume)
    Path:          /opt/cni/bin
    HostPathType:  
   cni:
    Type:          HostPath (bare host directory volume)
    Path:          /etc/cni/net.d
    HostPathType:  
   flannel-cfg:
    Type:      ConfigMap (a volume populated by a ConfigMap)
    Name:      kube-flannel-cfg
    Optional:  false
   xtables-lock:
    Type:               HostPath (bare host directory volume)
    Path:               /run/xtables.lock
    HostPathType:       FileOrCreate
  Priority Class Name:  system-node-critical
Events:
  Type    Reason            Age   From                  Message
  ----    ------            ----  ----                  -------
  Normal  SuccessfulCreate  17m   daemonset-controller  Created pod: kube-flannel-ds-f7clm

```

### Deploy a DaemonSet for FluentD Logging.


Use the given specifications.




    Name: elasticsearch
    
    Namespace: kube-system
    
    Image: registry.k8s.io/fluentd-elasticsearch:1.20


An easy way to create a DaemonSet is to first generate a YAML file for a Deployment with the command ```kubectl create deployment elasticsearch --image=registry.k8s.io/fluentd-elasticsearch:1.20 -n kube-system --dry-run=client -o yaml > fluentd.yaml```. Next, remove the replicas, strategy and status fields from the YAML file using a text editor. Also, change the kind from Deployment to DaemonSet.

Finally, create the Daemonset by running ```kubectl create -f fluentd.yaml```


Create a file ```fluentd.yaml``` with the content below:


      ---
      apiVersion: apps/v1
      kind: DaemonSet
      metadata:
        labels:
          app: elasticsearch
        name: elasticsearch
        namespace: kube-system
      spec:
        selector:
          matchLabels:
            app: elasticsearch
        template:
          metadata:
            labels:
              app: elasticsearch
          spec:
            containers:
            - image: registry.k8s.io/fluentd-elasticsearch:1.20
              name: fluentd-elasticsearch


Then run the following command: ```kubectl apply -f fluentd.yaml```



```ruby

controlplane ~ ➜  kubectl create deployment elasticsearch --image=registry.k8s.io/fluentd-elasticsearch:1.20 -n kube-system --dry-run=client -o yaml > fluentd.yaml

controlplane ~ ➜  LS
-bash: LS: command not found

controlplane ~ ✖ LS
-bash: LS: command not found

controlplane ~ ✖ ls
fluentd.yaml  sample.yaml

controlplane ~ ➜  cat fluentd.yaml 
apiVersion: apps/v1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    app: elasticsearch
  name: elasticsearch
  namespace: kube-system
spec:
  replicas: 1
  selector:
    matchLabels:
      app: elasticsearch
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: elasticsearch
    spec:
      containers:
      - image: registry.k8s.io/fluentd-elasticsearch:1.20
        name: fluentd-elasticsearch
        resources: {}
status: {}

controlplane ~ ➜  vi fluentd.yaml 

controlplane ~ ➜  kube
kubeadm  kubectl  kubelet  

controlplane ~ ➜  kubectl apply -f fluentd.yaml 
Error from server (BadRequest): error when creating "fluentd.yaml": DaemonSet in version "v1" cannot be handled as a DaemonSet: strict decoding error: unknown field "spec.replicas", unknown field "spec.strategy"

controlplane ~ ✖ vi fluentd.yaml 

controlplane ~ ➜  vi fluentd.yaml 

controlplane ~ ➜  kubectl apply -f fluentd.yaml 
daemonset.apps/elasticsearch created

controlplane ~ ➜  kubectl get daemonsets
No resources found in default namespace.

controlplane ~ ➜  kubectl get daemonset -n kube-system 
NAME            DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
elasticsearch   1         1         1       1            1           <none>                   29s
kube-proxy      1         1         1       1            1           kubernetes.io/os=linux   28m

controlplane ~ ➜  kubectl describe daemonset -n kube-system elasticsearch 
Name:           elasticsearch
Selector:       app=elasticsearch
Node-Selector:  <none>
Labels:         app=elasticsearch
Annotations:    deprecated.daemonset.template.generation: 1
Desired Number of Nodes Scheduled: 1
Current Number of Nodes Scheduled: 1
Number of Nodes Scheduled with Up-to-date Pods: 1
Number of Nodes Scheduled with Available Pods: 1
Number of Nodes Misscheduled: 0
Pods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed
Pod Template:
  Labels:  app=elasticsearch
  Containers:
   fluentd-elasticsearch:
    Image:        registry.k8s.io/fluentd-elasticsearch:1.20
    Port:         <none>
    Host Port:    <none>
    Environment:  <none>
    Mounts:       <none>
  Volumes:        <none>
Events:
  Type    Reason            Age   From                  Message
  ----    ------            ----  ----                  -------
  Normal  SuccessfulCreate  51s   daemonset-controller  Created pod: elasticsearch-4hh52

controlplane ~ ➜  cat fluentd.yaml 
apiVersion: apps/v1
kind: DaemonSet
metadata:
  creationTimestamp: null
  labels:
    app: elasticsearch
  name: elasticsearch
  namespace: kube-system
spec:
  selector:
    matchLabels:
      app: elasticsearch
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: elasticsearch
    spec:
      containers:
      - image: registry.k8s.io/fluentd-elasticsearch:1.20
        name: fluentd-elasticsearch
        resources: {}

```




