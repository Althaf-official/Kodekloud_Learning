### Construct a query to return all filesystems that have over 1000 bytes available on all instances under web job. Save the query in /root/query1.txt file.

The query should be node_filesystem_avail_bytes{job="web"} > 1000. To test the same, click on the Prometheus button to open the Prometheus UI and enter node_filesystem_avail_bytes{job="web"} > 1000 query in the expression browser, then click on Execute.


Further, save this query in /root/query1.txt file:


vi /root/query1.txt



Add node_filesystem_avail_bytes{job="web"} > 1000 query in this file and save.

![image](https://github.com/Althaf-official/Kodekloud_Learning/assets/105126131/851cdd43-2e40-4af9-9841-59e49356e49e)

### Which of the following queries you will use for loadbalancer:9100 host to return all the interfaces that have received less than or equal to 10000 bytes of traffic?

node_network_receive_bytes_total{instance="loadbalancer:9100"} <= 10000 query can be used for loadbalancer:9100 host to return all the interfaces that have received less than or equal to 10000 bytes of traffic.


#### node_filesystem_files tracks the filesystem's total file nodes. Construct a query that only returns time series greater than 500000 and less than 10000000 across all jobs. Save the same in /root/query3.txt file.


The query should be node_filesystem_files > 500000 and node_filesystem_files  < 10000000. To test the same, click on the Prometheus button to open the Prometheus UI and enter node_filesystem_files > 500000 and node_filesystem_files < 10000000 query in the expression browser, then click on Execute.


Further, save this query in /root/query3.txt file:


vi /root/query3.txt



Add node_filesystem_files > 500000 and node_filesystem_files < 10000000 query in this file and save.

### The metric node_filesystem_avail_bytes lists the available bytes for all filesystems, and the metric node_filesystem_size_bytes lists the total size of all filesystems. Run each metric and see their outputs. There are three properties/labels these will return, device, fstype, and mountpoint.


Which of the following queries will show the percentage of free disk space for all filesystems on all the targets under web job whose device label does not match tmpfs?


To match all filesystems that are not tmpfs, use the negative selector device!=tmpfs and set the job="web" to match all targets under web job. The final query would look like 
    node_filesystem_avail_bytes{job="web", device!="tmpfs"}*100 / node_filesystem_size_bytes{job="web", device!="tmpfs"}


### Which of the following queries can be used to track the total number of seconds cpu has spent in user + system mode for instance loadbalancer:9100?

To get the total time spent in user+system mode, run the query node_cpu_seconds_total{instance="loadbalancer:9100", mode="user"} + node_cpu_seconds_total{instance="loadbalancer:9100", mode="system"}, but this query will return no results, because the vector on the left will look for a vector on the right of the “+” operation, that matches the same labels. Since the vector on the left has mode="user" and vector on the right has mode="system", there will be no matches. So we have to ignore the mode label by adding an ignoring(mode). The final query will look like as below:


    node_cpu_seconds_total{instance="loadbalancer:9100", mode="user"} + ignoring(mode) node_cpu_seconds_total{instance="loadbalancer:9100", mode="system"}


    ![image](https://github.com/Althaf-official/Kodekloud_Learning/assets/105126131/865904ab-31e2-48ba-af86-c5070ff057fa)



### On loadbalancer:9100 instance, calculate the sum of the size of all filesystems. The metric to get filesystem size is node_filesystem_size_bytes. Save the query in /root/query6.txt file.

The query should be sum(node_filesystem_size_bytes{instance="loadbalancer:9100"}). To test the same, click on the Prometheus button to open the Prometheus UI and enter sum(node_filesystem_size_bytes{instance="loadbalancer:9100"}) query in the expression browser, then click on Execute.


Further, save this query in /root/query6.txt file:


vi /root/query6.txt



Add sum(node_filesystem_size_bytes{instance="loadbalancer:9100"}) query in this file and save.

#### Construct a query to find how many CPUs instance loadbalancer:9100 have. You can use the node_cpu_seconds_total metric to find out the same. Save the query in /root/query7.txt file.


With the node_cpu_seconds_total metric match one of the modes, doesn’t matter which one. This will show a time series for each cpu for that mode. Run a count operation to count how many total cpus the node have. So the query should be count(node_cpu_seconds_total{instance="loadbalancer:9100", mode="idle"}). To test the same, click on the Prometheus button to open the Prometheus UI and enter count(node_cpu_seconds_total{instance="loadbalancer:9100", mode="idle"}) query in the expression browser, then click on Execute.


Further, save this query in /root/query7.txt file:


vi /root/query7.txt



Add count(node_cpu_seconds_total{instance="loadbalancer:9100", mode="idle"}) query in this file and save.

![image](https://github.com/Althaf-official/Kodekloud_Learning/assets/105126131/53248051-b5c1-46da-b764-31df91e9a0ee)


### Construct a query that will show the number of CPUs on each instance across all jobs. Save the query in /root/query8.txt file.

For this query, we will again use the node_cpu_seconds_total and select some arbitrary mode like idle, but this time we will not select a specific instance. We’ll perform a count on that result which will count the total number of cpus across every instance. Then we would use a by clause to aggregate on instance, to find out how many cpus each instance has.


So, the query should be count by(instance) (node_cpu_seconds_total{ mode="idle"}). To test the same, click on the Prometheus button to open the Prometheus UI and enter count by(instance) (node_cpu_seconds_total{ mode="idle"}) query in the expression browser, then click on Execute.


Further, save this query in /root/query8.txt file:


vi /root/query8.txt



Add count by(instance) (node_cpu_seconds_total{ mode="idle"}) query in this file and save.

![image](https://github.com/Althaf-official/Kodekloud_Learning/assets/105126131/08126e3a-f532-4578-8db0-441f67fe84be)


### Use the node_network_receive_bytes_total metric to calculate the sum of the total received bytes across all interfaces on per instance basis. Save the query in /root/query9.txt file.


The query would be sum by(instance) (node_network_receive_bytes_total). To test the same, click on the Prometheus button to open the Prometheus UI and enter sum by(instance) (node_network_receive_bytes_total) query in the expression browser, then click on Execute.


Further, save this query in /root/query9.txt file:


vi /root/query9.txt



Add sum by(instance) (node_network_receive_bytes_total) query in this file and save.

![image](https://github.com/Althaf-official/Kodekloud_Learning/assets/105126131/d9420703-1a88-4dc9-add4-3e4a2c9c8117)

### Which of the following queries will be used to calculate the average packet size for each instance?

To get the per instance basis average packet size, get the sum of bytes received across all interfaces and divide it by packets received across all interfaces.


sum(node_network_receive_bytes_total) / sum (node_network_receive_packets_total)



Then we need to group them by instance, so add a by clause to both sides of the division operator.



sum by(instance)(node_network_receive_bytes_total) / sum by(instance)(node_network_receive_packets_total)


### Construct a query that will find out what percentage of time each cpu on each instance was spent in mode user. The final result should look like below, with a time series for each instance and cpu with x being the value of the timeseries


{cpu="0", instance="node1"} x


{cpu="1", instance="node1"} x


{cpu="0", instance="node2"} x


{cpu="1", instance="node2"} x


{cpu="0", instance="node3"} x


{cpu="1", instance="node3"} x


To calculate the percentage in mode user, get the total seconds spent in mode user and divide that by the sum of the time spent across all modes. Further, multiply that result by 100 to get a percentage.


### First, let’s get the sum of time spent across all modes. To do this use the sum operator.


sum(node_cpu_seconds_total)



The question asked to make sure we have the final result grouped by cpu and instance. To do so, add a group by clause to group it by cpu & instance


sum by(instance, cpu) (node_cpu_seconds_total)



For the top part of the equation, we just need to get the time spent in user mode which is:



node_cpu_seconds_total{mode="user"}



When dividing these two vectors, the vector on the top(left) has two extra labels(job, and mode). Make sure to ignore those when performing the division operation.



node_cpu_seconds_total{mode="user"} /ignoring(mode, job) sum by(instance, cpu) (node_cpu_seconds_total)



Lastly, multiply the result by 100 to get a percentage:



node_cpu_seconds_total{mode="user"}*100 /ignoring(mode, job) sum by(instance, cpu) (node_cpu_seconds_total)


#### The api job collects metrics on an API used for uploading files. The API has 3 endpoints /images /videos, and /songs, which are used to upload respective file types. The API provides 2 metrics to track


http_uploaded_bytes_total - tracks the number of uploaded bytes.


http_upload_failed_bytes_total - tracks the number of bytes failed to upload.


Construct a query to calculate the percentage of bytes that failed for each endpoint. The formula for the same is http_upload_failed_bytes_total*100 / http_uploaded_bytes_total.

If we try the equation directly, we get no results.


http_upload_failed_bytes_total*100 / http_uploaded_bytes_total



To understand why that is, take a look at the labels for each metric. Each metric has the following labels: -


http_upload_failed_bytes_total has - error and path

http_uploaded_bytes_total has - path


Notice how the first metric has an extra label. Because of that none of the vectors on the left of the equation will match with the right. So we will have to ignore the error label using the ignoring keyword.


http_upload_failed_bytes_total*100 / ignoring(error)  http_uploaded_bytes_total



If we run the above query, we now get an error. That is because for the metric http_upload_failed_bytes_total, there are two possible error codes for each path. Since we are ignoring error label, that means multiple time series on the left will match with a single time series on the right.


We will need to use the group_left keyword so that the final query will look like as below:


http_upload_failed_bytes_total*100 / ignoring(error) group_left http_uploaded_bytes_total


