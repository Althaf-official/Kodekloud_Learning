### The Node exporter is already installed on both nodes, i.e., node01 and node02. Now, let's configure the node exporter on both nodes as below:


Create a directory called node_exporter under /etc.
Create a blank file called config.yml under this newly created directory.
Set appropriate permissions for node_exporter directory and config.yml file. The node exporter username on both nodes is nodeusr
Finally, edit the node exporter service, i.e., /etc/systemd/system/node_exporter.service to use config.yml config file.
Make sure to restart the node_exporter service once done.


Note: You should be able to SSH into node01 and node02 through user root (without any password) from prometheus-server. Once you SSH into any node (for example node01) and you are done with your changes, remember to exit from that node (i.e node01) before SSH into the another node (i.e node02).


## node 2
```ruby

root@prometheus-server ~ ➜  ssh root@node02
Welcome to Ubuntu 20.04.5 LTS (GNU/Linux 5.4.0-1106-gcp x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

This system has been minimized by removing packages and content that are
not required on a system that users do not log into.

To restore this content, you can run the 'unminimize' command.

root@node02 ~ ➜  mkdir /etc/node_exporter/

root@node02 ~ ➜  touch /etc/node_exporter/config.yml

root@node02 ~ ➜  chmod 700 /etc/node_exporter

root@node02 ~ ➜  chmod 600 /etc/node_exporter/config.yml

root@node02 ~ ➜  chown -R nodeusr:nodeusr /etc/node_exporter

root@node02 ~ ➜  vi /etc/systemd/system/node_exporter.service

root@node02 ~ ➜  cat /etc/systemd/system/node_exporter.service
[Unit]
Description=Node Exporter
After=network.target

[Service]
User=nodeusr
Group=nodeusr
Type=simple
ExecStart=/usr/local/bin/node_exporter --web.config=/etc/node_exporter/config.yml

[Install]
WantedBy=multi-user.target

root@node02 ~ ➜  systemctl daemon-reload

root@node02 ~ ➜  systemctl restart node_exporter

root@node02 ~ ➜  exit
logout
Connection to node02 closed.

root@prometheus-server ~ ➜  
```

SSH to node01


    ssh root@node01



Create the config:


    mkdir /etc/node_exporter/
    touch /etc/node_exporter/config.yml
    chmod 700 /etc/node_exporter
    chmod 600 /etc/node_exporter/config.yml
    chown -R nodeusr:nodeusr /etc/node_exporter



Edit node_exporter service


    vi /etc/systemd/system/node_exporter.service



Change below line:


    ExecStart=/usr/local/bin/node_exporter


to

    ExecStart=/usr/local/bin/node_exporter --web.config=/etc/node_exporter/config.yml



Reload the daemon and Restart node_exporter service


    systemctl daemon-reload
    systemctl restart node_exporter
    exit

----


### Configure Prometheus and Node servers to use authentication to communicate. Find more details below:


  (a) Username should be prometheus.


  (b) Password should be secret-password, use the apache2-utils package to create a hash of the password.


  (c) Configure node exporter's config file, i.e., config.yml to use the authentication


  (d) Finally, restart node exporter service once done.


```ruby
root@node01 ~ ➜  htpasswd -nBC 10 "" | tr -d ':\n'; echo
New password: 
Re-type new password: 
$2y$10$hDTRAShKTvMkUQZ0ekeAEOPurXLuRBqlkKL0VgpvGZcy8Fu3LOt9W

root@node01 ~ ➜  vi /etc/node_exporter/config.yml

root@node01 ~ ➜  vi /etc/node_exporter/config.yml

root@node01 ~ ➜  cat /etc/node_exporter/config.yml
basic_auth_users:
  prometheus: $2y$10$hDTRAShKTvMkUQZ0ekeAEOPurXLuRBqlkKL0VgpvGZcy8Fu3LOt9W

root@node01 ~ ➜  systemctl restart node_exporter

root@node01 ~ ➜  curl http://node01:9100/metrics
Unauthorized

------------


root@prometheus-server ~ ➜  ssh root@node02
Warning: Permanently added the ECDSA host key for IP address '192.16.1.3' to the list of known hosts.
Welcome to Ubuntu 20.04.5 LTS (GNU/Linux 5.4.0-1106-gcp x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

This system has been minimized by removing packages and content that are
not required on a system that users do not log into.

To restore this content, you can run the 'unminimize' command.
Last login: Tue Jan 16 10:55:23 2024 from 192.16.1.13

root@node02 ~ ➜  apt update
Get:1 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]
Get:2 http://archive.ubuntu.com/ubuntu focal InRelease [265 kB]       
Get:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]
Get:4 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [29.7 kB]
Get:5 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]
Get:6 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [3,290 kB]
Get:7 http://archive.ubuntu.com/ubuntu focal/multiverse amd64 Packages [177 kB]
Get:8 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [3,142 kB]
Get:9 http://archive.ubuntu.com/ubuntu focal/restricted amd64 Packages [33.4 kB]
Get:10 http://archive.ubuntu.com/ubuntu focal/universe amd64 Packages [11.3 MB]              
Get:11 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,156 kB]   
Get:12 http://archive.ubuntu.com/ubuntu focal/main amd64 Packages [1,275 kB]                
Get:13 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,770 kB]
Get:14 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,450 kB]
Get:15 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [3,292 kB]
Get:16 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [32.4 kB]
Get:17 http://archive.ubuntu.com/ubuntu focal-backports/main amd64 Packages [55.2 kB]
Get:18 http://archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [28.6 kB]
Fetched 29.7 MB in 2s (12.8 MB/s)                            
Reading package lists... Done
Building dependency tree       
Reading state information... Done
153 packages can be upgraded. Run 'apt list --upgradable' to see them.

root@node02 ~ ➜  apt install apache2-utils -y
Reading package lists... Done
Building dependency tree       
Reading state information... Done
The following additional packages will be installed:
  libapr1 libaprutil1
The following NEW packages will be installed:
  apache2-utils libapr1 libaprutil1
0 upgraded, 3 newly installed, 0 to remove and 153 not upgraded.
Need to get 261 kB of archives.
After this operation, 971 kB of additional disk space will be used.
Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 libapr1 amd64 1.6.5-1ubuntu1 [91.4 kB]
Get:2 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 libaprutil1 amd64 1.6.1-4ubuntu2.2 [85.1 kB]
Get:3 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 apache2-utils amd64 2.4.41-4ubuntu3.15 [84.1 kB]
Fetched 261 kB in 0s (765 kB/s)         
debconf: delaying package configuration, since apt-utils is not installed
Selecting previously unselected package libapr1:amd64.
(Reading database ... 25254 files and directories currently installed.)
Preparing to unpack .../libapr1_1.6.5-1ubuntu1_amd64.deb ...
Unpacking libapr1:amd64 (1.6.5-1ubuntu1) ...
Selecting previously unselected package libaprutil1:amd64.
Preparing to unpack .../libaprutil1_1.6.1-4ubuntu2.2_amd64.deb ...
Unpacking libaprutil1:amd64 (1.6.1-4ubuntu2.2) ...
Selecting previously unselected package apache2-utils.
Preparing to unpack .../apache2-utils_2.4.41-4ubuntu3.15_amd64.deb ...
Unpacking apache2-utils (2.4.41-4ubuntu3.15) ...
Setting up libapr1:amd64 (1.6.5-1ubuntu1) ...
Setting up libaprutil1:amd64 (1.6.1-4ubuntu2.2) ...
Setting up apache2-utils (2.4.41-4ubuntu3.15) ...
Processing triggers for libc-bin (2.31-0ubuntu9.9) ...

root@node02 ~ ➜  htpasswd -nBC 10 "" | tr -d ':\n'; echo
New password: 
Re-type new password: 
$2y$10$xWa9rjBT9/PVIM/eoGjuuu7UQ5FfkhbIaNsFEimA0AgZTN44QEaLq

root@node02 ~ ➜  vi /etc/node_exporter/config.yml

root@node02 ~ ➜  cat /etc/node_exporter/config.yml
basic_auth_users:
  prometheus: $2y$10$xWa9rjBT9/PVIM/eoGjuuu7UQ5FfkhbIaNsFEimA0AgZTN44QEaLq

root@node02 ~ ➜  systemctl restart node_exporter

root@node02 ~ ➜  curl http://node01:9100/metrics
Unauthorized

root@node02 ~ ➜  exit
logout
Connection to node02 closed.

root@prometheus-server ~ ➜  curl http://node01:9100/metrics
Unauthorized

root@prometheus-server ~ ➜  
```

Note: You should be able to SSH into node01 and node02 through user root (without any password) from prometheus-server. Once you SSH into any node (for example node01) and you are done with your changes, remember to exit from that node (i.e node01) before SSH into the another node (i.e node02).

SSH to node01:


ssh root@node01



Install apache2-utils package:


apt update
apt install apache2-utils -y



Generate password hash:

htpasswd -nBC 10 "" | tr -d ':\n'; echo



It will ask for the password twice as below (enter password secret-password twice):


New password: 
Re-type new password: 



Finally, you will get a hashed value of your password.


Edit /etc/node_exporter/config.yml file:


vi /etc/node_exporter/config.yml



Add below lines in it:


basic_auth_users:
  prometheus: <hashed-password>



Restart node_exporter service


systemctl restart node_exporter
exit



You can verify the changes using curl command:

curl http://node01:9100/metrics



return output should be Unauthorized


Note: Follow same steps for node02 except generating the password hash, you should be able to use the same password hash for node02.


### Are you able to access the metrics using correct credentials now?

Try using below given commands:


    curl -u prometheus:secret-password http://node01:9100/metrics
    curl -u prometheus:secret-password http://node02:9100/metrics


    You should be able to retrieve the metrics using correct credentials.

### Access the Prometheus UI using Prometheus button on the top bar.



What is the status of nodes under targets and error code if nodes are down?

![image](https://github.com/Althaf-official/Kodekloud_Learning/assets/105126131/1cf38c8e-2159-4c8d-84b9-2a823f32568d)

### Now, let's configure the Prometheus server to use authentication when scraping metrics from node servers.

```ruby
root@prometheus-server ~ ➜  vi /etc/prometheus/prometheus.yml

root@prometheus-server ~ ➜  cat /etc/prometheus/prometheus.yml
# my global config
global:
  scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).

# Alertmanager configuration
alerting:
  alertmanagers:
    - static_configs:
        - targets:
          # - alertmanager:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: "prometheus"

    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.

    static_configs:
      - targets: ["localhost:9090"]

  - job_name: "nodes"
    static_configs:
      - targets: ["node01:9100", "node02:9100"]
    basic_auth:
      username: prometheus
      password: secret-password

root@prometheus-server ~ ➜  systemctl restart prometheus

root@prometheus-server ~ ➜  
```


Edit the Prometheus configuration file


    vi /etc/prometheus/prometheus.yml



Under - job_name: "nodes" add below lines:


    basic_auth:
      username: prometheus
      password: secret-password



Restart prometheus service:


    systemctl restart prometheus


### Configure node exporter to use TLS on both nodes i.e node01 and node02. You can generate a certificate and key using the below command:

    openssl req -new -newkey rsa:2048 -days 365 -nodes -x509 -keyout node_exporter.key -out node_exporter.crt -subj "/C=US/ST=California/L=Oakland/O=MyOrg/CN=localhost" -addext "subjectAltName = DNS:localhost"

```ruby
root@prometheus-server ~ ➜  ssh root@node02
Welcome to Ubuntu 20.04.5 LTS (GNU/Linux 5.4.0-1106-gcp x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

This system has been minimized by removing packages and content that are
not required on a system that users do not log into.

To restore this content, you can run the 'unminimize' command.
Last login: Tue Jan 16 10:59:30 2024 from 192.16.1.12

root@node02 ~ ➜  openssl req -new -newkey rsa:2048 -days 365 -nodes -x509 -keyout node_exporter.key -out node_exporter.crt -subj "/C=US/ST=California/L=Oakland/O=MyOrg/CN=localhost" -addext "subjectAltName = DNS:localhost"
Generating a RSA private key
.......................................................................+++++
.................................................................+++++
writing new private key to 'node_exporter.key'
-----

root@node02 ~ ➜  mv node_exporter.crt node_exporter.key /etc/node_exporter/

root@node02 ~ ➜  chown nodeusr.nodeusr /etc/node_exporter/node_exporter.key

root@node02 ~ ➜  chown nodeusr.nodeusr /etc/node_exporter/node_exporter.crt

root@node02 ~ ➜  vi /etc/node_exporter/config.yml

root@node02 ~ ➜  cat /etc/node_exporter/config.yml
basic_auth_users:
  prometheus: $2y$10$xWa9rjBT9/PVIM/eoGjuuu7UQ5FfkhbIaNsFEimA0AgZTN44QEaLq
tls_server_config:
  cert_file: node_exporter.crt
  key_file: node_exporter.key

root@node02 ~ ➜  systemctl restart node_exporter

root@node02 ~ ➜  
```

SSH to node01

    
    ssh root@node01



Generate the certificate and key


    openssl req -new -newkey rsa:2048 -days 365 -nodes -x509 -keyout node_exporter.key -out node_exporter.crt -subj "/C=US/ST=California/L=Oakland/O=MyOrg/CN=localhost" -addext "subjectAltName = DNS:localhost"



Move the crt and key file under /etc/node_exporter/ directory

    mv node_exporter.crt node_exporter.key /etc/node_exporter/



Change ownership:


    chown nodeusr.nodeusr /etc/node_exporter/node_exporter.key
    chown nodeusr.nodeusr /etc/node_exporter/node_exporter.crt



Edit /etc/node_exporter/config.yml file:


    vi /etc/node_exporter/config.yml



Add below lines in this file:

    
    tls_server_config:
      cert_file: node_exporter.crt
      key_file: node_exporter.key



Restart node exporter service:


    systemctl restart node_exporter
    exit



You can verify your changes using curl command:


    curl -u prometheus:secret-password -k https://node01:9100/metrics



Follow same steps for node02


### Access the Prometheus UI using Prometheus button on the top bar.



What is the status of nodes under targets and error code if nodes are down?


    Click on the Prometheus button to access the Prometheus UI. Go to Status -> Targets and look for the status of nodes under targets. These must be DOWN with 400 Bad Request error.

![image](https://github.com/Althaf-official/Kodekloud_Learning/assets/105126131/742e3e31-ea49-4cca-aeff-ac88e0745016)



#### Let's configure Prometheus server to use HTTPS for scraping the node_exporter. Find below more details:



  (a) Copy the certificate from node_exporter to the prometheus server.


  (b) Update prometheus config to use https for node_exporter


  (c) Make sure to add insecure_skip_verify: true since we are using a self signed certificate


  (d) Finally restart the prometheus service.


  ```ruby
root@prometheus-server ~ ➜  

root@prometheus-server ~ ➜  

root@prometheus-server ~ ➜  scp root@node01:/etc/node_exporter/node_exporter.crt /etc/prometheus/node_exporter.crt
Warning: Permanently added the ECDSA host key for IP address '192.16.1.14' to the list of known hosts.
node_exporter.crt                                            100% 1326     2.2MB/s   00:00    

root@prometheus-server ~ ➜  chown prometheus.prometheus /etc/prometheus/node_exporter.crt

root@prometheus-server ~ ➜  vi /etc/prometheus/prometheus.yml 

root@prometheus-server ~ ➜  systemctl restart prometheus

root@prometheus-server ~ ➜  cat /etc/prometheus/prometheus.yml 
# my global config
global:
  scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).

# Alertmanager configuration
alerting:
  alertmanagers:
    - static_configs:
        - targets:
          # - alertmanager:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: "prometheus"

    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.

    static_configs:
      - targets: ["localhost:9090"]

  - job_name: "nodes"
    static_configs:
      - targets: ["node01:9100", "node02:9100"]
    basic_auth:
      username: prometheus
      password: secret-password
    scheme: https
    tls_config:
      ca_file: /etc/prometheus/node_exporter.crt
      insecure_skip_verify: true

root@prometheus-server ~ ➜  
```


Copy the certificate from node01 to Prometheus server

    
    scp root@node01:/etc/node_exporter/node_exporter.crt /etc/prometheus/node_exporter.crt



Change certificate file ownership:


    chown prometheus.prometheus /etc/prometheus/node_exporter.crt



Edit /etc/prometheus/prometheus.yml file

    
    vi /etc/prometheus/prometheus.yml 



Add below given lines under - job_name: "nodes"


        scheme: https
        tls_config:
          ca_file: /etc/prometheus/node_exporter.crt
          insecure_skip_verify: true



Restart prometheus service

    systemctl restart prometheus



### Access the Prometheus UI using Prometheus button on the top bar.



Under Status -> Targets you will see that both nodes are getting scrapped over https endpoints.


![image](https://github.com/Althaf-official/Kodekloud_Learning/assets/105126131/764b07f7-49aa-4b63-a252-c78adfc68643)


