Create a recording rule to track the rate at which a node is receiving traffic. Find below more details:
  (a) Create a file called node-rules.yaml under /etc/prometheus directory.
  (b) Update this file to:
        (i) Create a group called node, this group should have all the rules for node_exporters.
        (ii) Set the interval for the rules to run every 15s.
        (iii) Add a record called node_network_receive_bytes_rate.
        (iv) The expression should be rate(node_network_receive_bytes_total{job="nodes"}[2m])
  (c) Finally, update the prometheus.yml file to import rules from node-rules.yaml file and restart the prometheus service.


Create a new file /etc/prometheus/node-rules.yaml:


vi /etc/prometheus/node-rules.yaml



Add below lines in it:


    groups:
      - name: node
        interval: 15s
        rules:
          - record: node_network_receive_bytes_rate
            expr: rate(node_network_receive_bytes_total{job="nodes"}[2m])



Edit /etc/prometheus/prometheus.yml file:


    vi /etc/prometheus/prometheus.yml



Add below line under rule_files: section:


      - "node-rules.yaml"



Restart the prometheus service:


    systemctl restart prometheus



![image](https://github.com/Althaf-official/Kodekloud_Learning/assets/105126131/a29ef776-90ec-4ca9-b76e-d9fc584acf91)


![image](https://github.com/Althaf-official/Kodekloud_Learning/assets/105126131/f546830c-f5fe-4869-ba8c-7f834ee1ab16)

```ruby
root@prometheus-server ~ ➜  vi /etc/prometheus/node-rules.yaml

root@prometheus-server ~ ➜  ls

root@prometheus-server ~ ➜  cd /etc/prometheus/

root@prometheus-server /etc/prometheus ➜  ls
console_libraries  node-rules.yaml    node_exporter.key
consoles           node_exporter.crt  prometheus.yml

root@prometheus-server /etc/prometheus ➜  cat prometheus.yml 
# my global config
global:
  scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).

# Alertmanager configuration
alerting:
  alertmanagers:
    - static_configs:
        - targets:
          # - alertmanager:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: "prometheus"

    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.

    static_configs:
      - targets: ["localhost:9090"]

  - job_name: "nodes"
    scheme: https
    tls_config:
      ca_file: /etc/prometheus/node_exporter.crt
      insecure_skip_verify: true
    basic_auth:
      username: prometheus
      password: secret-password
    static_configs:
      - targets: ["node01:9100", "node02:9100"]

  - job_name: "api"
    static_configs:
      - targets: ["node01:3000", "node02:3000"]

root@prometheus-server /etc/prometheus ➜  ls
console_libraries  node-rules.yaml    node_exporter.key
consoles           node_exporter.crt  prometheus.yml

root@prometheus-server /etc/prometheus ➜  cat node
cat: node: No such file or directory

root@prometheus-server /etc/prometheus ✖ cat node-rules.yaml 
groups:
  - name: node
    interval: 15s
    rules:
      - record: node_network_receive_bytes_rate
        expr: rate(node_network_receive_bytes_total{job="nodes"}[2m])

root@prometheus-server /etc/prometheus ➜  vi /etc/prometheus/prometheus.yml

root@prometheus-server /etc/prometheus ➜  cat prometheus.yml 
# my global config
global:
  scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).

# Alertmanager configuration
alerting:
  alertmanagers:
    - static_configs:
        - targets:
          # - alertmanager:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"
    - "node-rules.yaml"
# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: "prometheus"

    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.

    static_configs:
      - targets: ["localhost:9090"]

  - job_name: "nodes"
    scheme: https
    tls_config:
      ca_file: /etc/prometheus/node_exporter.crt
      insecure_skip_verify: true
    basic_auth:
      username: prometheus
      password: secret-password
    static_configs:
      - targets: ["node01:9100", "node02:9100"]

  - job_name: "api"
    static_configs:
      - targets: ["node01:3000", "node02:3000"]

root@prometheus-server /etc/prometheus ➜  systemctl restart prometheus

root@prometheus-server /etc/prometheus ➜  
```

### Update the node group you created earlier to add another rule to get the average rate of received packets across all interfaces on a node, as each node has 2 interfaces. Please find below more details:



  (a) The record name should be node_network_receive_bytes_rate_avg.


  (b) The expression should be:


avg by(instance) (node_network_receive_bytes_rate)

----

Edit /etc/prometheus/node-rules.yaml file:


    vi /etc/prometheus/node-rules.yaml



Add the required rule so that the file looks like below:


    groups:
      - name: node
        interval: 15s
        rules:
          - record: node_network_receive_bytes_rate
            expr: rate(node_network_receive_bytes_total{job="nodes"}[2m])
          - record: node_network_receive_bytes_rate_avg
            expr: avg by(instance) (node_network_receive_bytes_rate)



Restart the prometheus service:


    systemctl restart prometheus



![image](https://github.com/Althaf-official/Kodekloud_Learning/assets/105126131/27d81eb4-8254-4815-9312-20ebee38ac4e)


### Update the node group to add another rule to track the filesystem free space percentage. Find below more details:



   (a) The record name should be node_filesystem_free_percent.


   (b) The expression should be 100 * node_filesystem_free_bytes{job="nodes"} / node_filesystem_size_bytes{job="nodes"}


  (c) Restart the prometheus service.



Edit /etc/prometheus/node-rules.yaml file:

    
    vi /etc/prometheus/node-rules.yaml



Add the required rule so that the file looks like below:


    groups:
      - name: node
        interval: 15s
        rules:
          - record: node_network_receive_bytes_rate
            expr: rate(node_network_receive_bytes_total{job="nodes"}[2m])
          - record: node_network_receive_bytes_rate_avg
            expr: avg by(instance) (node_network_receive_bytes_rate)
          - record: node_filesystem_free_percent
            expr: 100 * node_filesystem_free_bytes{job="nodes"} / node_filesystem_size_bytes{job="nodes"}



Restart the prometheus service:


    systemctl restart prometheus




![image](https://github.com/Althaf-official/Kodekloud_Learning/assets/105126131/5a93f7ea-0cf5-45a1-aaec-ad6612ab8bd0)



### Create a new file called api-rules.yaml under /etc/prometheus/ directory. Update it to configure below rule(s).



  (a) Add a group called api.


  (b) Set the interval to 15s


  (c) Add a rule that will track the average latency for past 2 minutes:


        (i) The record name should be avg_latency_2m.


        (ii) The expression should be rate(http_request_total_sum{job="api"}[2m]) /
        rate(http_request_total_count{job="api"}[2m])


  (d) Update the prometheus.yml file to include the new rules file i.e api-rules.yaml.


  (e) Restart the Prometheus service.



Create a new file /etc/prometheus/api-rules.yaml:


    vi /etc/prometheus/api-rules.yaml



Add below lines in it:


    groups:
      - name: api
        interval: 15s
        rules:
          - record: avg_latency_2m
            expr: rate(http_request_total_sum{job="api"}[2m]) / rate(http_request_total_count{job="api"}[2m])



Edit /etc/prometheus/prometheus.yml file:


vi /etc/prometheus/prometheus.yml



Add below line under rule_files: section:


      - "api-rules.yaml"



Restart prometheus service:


    systemctl restart prometheus



![image](https://github.com/Althaf-official/Kodekloud_Learning/assets/105126131/c445b7fb-16e6-4363-9f26-8dbba233e333)


![image](https://github.com/Althaf-official/Kodekloud_Learning/assets/105126131/dbff139d-5d56-4038-bf29-5c0a8bab68ac)


### We can avoid updating the prometheus.yml file every time for adding a new rule file we create by making use of globs. Update the prometheus.yml file so that it look like below:



    rule_files:
      - "*rules.yaml"



This will import all files that have prefix rules.yaml. Finally, restart theprometheus service.

Edit /etc/prometheus/prometheus.yml file:


    vi /etc/prometheus/prometheus.yml



Change rule_files: section so that it looks like below:

    
    rule_files:
      - "*rules.yaml"



Restart the prometheus service:

    
    systemctl restart prometheus


```ruby
root@prometheus-server /etc/prometheus ➜  vi /etc/prometheus/prometheus.yml

root@prometheus-server /etc/prometheus ➜  systemctl restart prometheus

root@prometheus-server /etc/prometheus ➜  cat /etc/prometheus/prometheus.yml
# my global config
global:
  scrape_interval: 15s # Set the scrape interval to every 15 seconds. Default is every 1 minute.
  evaluation_interval: 15s # Evaluate rules every 15 seconds. The default is every 1 minute.
  # scrape_timeout is set to the global default (10s).

# Alertmanager configuration
alerting:
  alertmanagers:
    - static_configs:
        - targets:
          # - alertmanager:9093

# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"
    - "node-rules.yaml"
    - "api-rules.yaml"
    - "*rules.yaml"
# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: "prometheus"

    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.

    static_configs:
      - targets: ["localhost:9090"]

  - job_name: "nodes"
    scheme: https
    tls_config:
      ca_file: /etc/prometheus/node_exporter.crt
      insecure_skip_verify: true
    basic_auth:
      username: prometheus
      password: secret-password
    static_configs:
      - targets: ["node01:9100", "node02:9100"]

  - job_name: "api"
    static_configs:
      - targets: ["node01:3000", "node02:3000"]

root@prometheus-server /etc/prometheus ➜  
```

![image](https://github.com/Althaf-official/Kodekloud_Learning/assets/105126131/4865d8ed-0a8f-4f6f-b51f-6309f772def7)
